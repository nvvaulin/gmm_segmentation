{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR (theano.gpuarray): Could not initialize pygpu, support disabled\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/theano/gpuarray/__init__.py\", line 164, in <module>\n",
      "    use(config.device)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/theano/gpuarray/__init__.py\", line 151, in use\n",
      "    init_dev(device)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/theano/gpuarray/__init__.py\", line 60, in init_dev\n",
      "    sched=config.gpuarray.sched)\n",
      "  File \"pygpu/gpuarray.pyx\", line 614, in pygpu.gpuarray.init (pygpu/gpuarray.c:9415)\n",
      "  File \"pygpu/gpuarray.pyx\", line 566, in pygpu.gpuarray.pygpu_init (pygpu/gpuarray.c:9106)\n",
      "  File \"pygpu/gpuarray.pyx\", line 1021, in pygpu.gpuarray.GpuContext.__cinit__ (pygpu/gpuarray.c:13468)\n",
      "GpuArrayException: Unknown device error: -1\n"
     ]
    }
   ],
   "source": [
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "import theano\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lasagne import layers as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pack_mcw(m,c,w):\n",
    "    '''\n",
    "    m = batch,gm_num,dim\n",
    "    c = batch,gm_num\n",
    "    w = batch,gm_num\n",
    "    ''' \n",
    "    return T.concatenate([m,c.reshape((c.shape[0],c.shape[1],1)),w.reshape((w.shape[0],w.shape[1],1))],2)\n",
    "    \n",
    "def unpack_mcw(mcw):\n",
    "    '''\n",
    "    mcw = batch,gm_num,[ndim,c,w]\n",
    "    return  m = batch,gm_num,dim\n",
    "            c = batch,gm_num\n",
    "            w = batch,gm_num\n",
    "    ''' \n",
    "    return mcw[:,:,:-2],mcw[:,:,-2],mcw[:,:,-1]\n",
    "\n",
    "def iterative_update(m,c,w,m0,c0,w0,eps=1e-10):\n",
    "    '''\n",
    "    m = batch,gm_num,dim\n",
    "    c = batch,gm_num\n",
    "    w = batch,gm_num\n",
    "    m0 = batch,dim\n",
    "    c0 = batch\n",
    "    w0 = batch\n",
    "    return m,c,w\n",
    "    ''' \n",
    "    #add component correspoding to X\n",
    "    m0 = m0.reshape((m0.shape[0],1,m0.shape[1]))\n",
    "    m = T.concatenate((m,m0),1)\n",
    "    c = T.concatenate((c,c0.reshape((c0.shape[0],1))),1)\n",
    "    w = T.concatenate((w,w0.reshape((w0.shape[0],1))),1)\n",
    "    w = w/T.sum(w,1)[:,None]\n",
    "    \n",
    "    #split components\n",
    "    dist = m[:,:,None,:]-m[:,None,:,:]\n",
    "    dist = T.sum(T.square(dist),-1)*w[:,None,:]*w[:,:,None]\n",
    "    batched_eye = T.zeros_like(dist)+T.eye(dist.shape[1],dtype=dist.dtype)[None,:,:]\n",
    "    dist = dist+batched_eye*dist.max()\n",
    "    dist = T.min(dist,-1)\n",
    "    inx = T.argsort(dist,-1)\n",
    "    inx += (T.arange(0,dist.shape[0],dtype=inx.dtype)*dist.shape[1])[:,None]\n",
    "    inx = inx.flatten()\n",
    "    m = m.reshape((m.shape[0]*m.shape[1],m.shape[2]))[inx].reshape(m.shape)\n",
    "    c = c.flatten()[inx].reshape(c.shape)\n",
    "    w = w.flatten()[inx].reshape(w.shape)\n",
    "    \n",
    "    m0 = m[:,:2,:]\n",
    "    c0 = c[:,:2]\n",
    "    w0 = w[:,:2]\n",
    "    \n",
    "    m = m[:,2:,:]\n",
    "    c = c[:,2:]\n",
    "    w = w[:,2:]\n",
    "    \n",
    "    #merge components\n",
    "    ww =w0/T.sum(w0,-1)[:,None]\n",
    "    _m0 = T.sum(m0*ww[:,:,None],1,keepdims=True)\n",
    "    _c0 = T.sum((c0+T.sum(T.square(_m0-m0),-1))*ww,1,keepdims=True)\n",
    "    _w0 = T.sum(w0,1,keepdims=True)\n",
    "    \n",
    "    m = T.concatenate([m,_m0],1)\n",
    "    c = T.concatenate([c,_c0],1)\n",
    "    w = T.concatenate([w,_w0],1)\n",
    "    return m,c,w\n",
    "\n",
    "\n",
    "def componentwise_score_gmm(X,m,c,eps=1e-7):\n",
    "    '''\n",
    "    calculate loglikelihood for each gaussian in mixture\n",
    "    X - batch,samples,dim\n",
    "    m - batch,gm_num,dim\n",
    "    c - batch,gm_num\n",
    "    w - batch,gm_num\n",
    "    return tensor3 batch,samples,gm_num\n",
    "    '''\n",
    "    dist = T.sum(T.square(X[:,:,None,:] - m[:,None,:,:]),-1)/(c[:,None,:]+eps)\n",
    "    norm = (T.log(2.*np.pi)+c)*X.shape[-1]\n",
    "    return -0.5*(norm[:,None,:]+dist)\n",
    "\n",
    "def score_gmm(X,m,c,w,eps=1e-7):\n",
    "    '''\n",
    "    calculate loglikelihood for gaussian mixture\n",
    "    X - batch,samples,dim\n",
    "    m - batch,gm_num,dim\n",
    "    c - batch,gm_num\n",
    "    w - batch,gm_num\n",
    "    return matrix batch,samples\n",
    "    '''\n",
    "    lprob = componentwise_score_gmm(X,m,c,eps)+T.log(w+eps)[:,None,:]\n",
    "    lmax = T.max(lprob,-1)\n",
    "    return T.log(T.sum(T.exp(lprob-lmax[:,:,None]),-1)+1e-10)+lmax\n",
    "\n",
    "        \n",
    "# X,m,c,w,c0,w0 = T.matrix(),T.tensor3(),T.matrix(),T.matrix(),T.vector(),T.vector()\n",
    "# iu  =iterative_update(m,c,w,X,c0,w0)\n",
    "# f = theano.function([X,m,c,w,c0,w0],iu,allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "class ScoreGMMLayer(L.MergeLayer):\n",
    "    '''\n",
    "    calculate loglikelihood for gaussian mixture\n",
    "    X - batch,samples,dim\n",
    "    mcw - batch,gm_num,dim+2\n",
    "    return matrix batch,samples\n",
    "    '''\n",
    "    def __init__(self,X,mcw,eps=1e-7,name=\"score_gmm\",**kwargs):\n",
    "        super(ScoreGMMLayer,self).__init__([X,mcw],name=name,**kwargs)\n",
    "        self.eps=eps\n",
    "        \n",
    "    def get_output_shape_for(self,input_shape):\n",
    "        assert(len(input_shape[0]) == 3)\n",
    "        assert(len(input_shape[1]) == 3)\n",
    "        assert(input_shape[0][0] == input_shape[1][0] and input_shape[0][2]+2 == input_shape[1][2])\n",
    "        return input_shape[0][:2]\n",
    "        \n",
    "    def get_output_for(self, input, **kwargs):\n",
    "        m,c,w = unpack_mcw(input[1])\n",
    "        X = input[0]\n",
    "        return score_gmm(X,m,c,w,self.eps)\n",
    "\n",
    "class UpdateGMMLayer(L.MergeLayer):\n",
    "    '''\n",
    "    update gmm parameters\n",
    "    Xcw - batch,dim+2\n",
    "    mcw - batch,gm_num,dim+2\n",
    "    \n",
    "    '''\n",
    "    def __init__(self,Xcw,mcw,eps=1e-7,name=\"update_gmm\",**kwargs):\n",
    "        super(UpdateGMMLayer,self).__init__([Xcw,mcw],name=name,**kwargs)\n",
    "        self.eps = eps\n",
    "        \n",
    "    def get_output_shape_for(self,input_shape):\n",
    "        assert(len(input_shape[1]) == 3)\n",
    "        assert(len(input_shape[0]) == 2)\n",
    "        assert(input_shape[1][0] == input_shape[0][0] and input_shape[0][1] == input_shape[1][2])\n",
    "        return input_shape[1]\n",
    "        \n",
    "    def get_output_for(self, input, **kwargs):\n",
    "        m,c,w = unpack_mcw(input[1])\n",
    "        X = input[0]\n",
    "        m0 = X[:,:-2]\n",
    "        c0 = X[:,-2]\n",
    "        w0 = X[:,-1]\n",
    "        m,c,w = iterative_update(m,c,w,m0,c0,w0,self.eps) \n",
    "        return pack_mcw(m,c,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "def gen_mixture(ns,dim,sigm=.3):\n",
    "    ns = np.array(ns)\n",
    "    means = []\n",
    "    covs = []\n",
    "    weights = ns.astype(np.float32)/ns.sum()\n",
    "    res = np.zeros((int(sum(ns)),dim),dtype=np.float32)\n",
    "    i = 0\n",
    "    for n in ns:\n",
    "        covs.append(sigm*(np.random.rand(dim)+1.))\n",
    "        means.append(10*(np.random.rand(dim)))\n",
    "        res[i:i+n] = np.random.randn(n,dim)*covs[-1][None,:]+means[-1][None,:]\n",
    "        covs[-1] = np.std(res[i:i+n],0)**2\n",
    "        means[-1] = np.mean(res[i:i+n],0)\n",
    "        i=i+n\n",
    "    return res,np.array(means),np.array(covs),weights\n",
    "\n",
    "X,tm,tc,tw = gen_mixture([200,300,200,100],2,0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8f4d73a6d0>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8f4d73af50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X[:,0],X[:,1],'o')\n",
    "plt.plot(tm[:,0],tm[:,1],'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(X)\n",
    "\n",
    "L.get_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = X[:4].reshape((1,4,-1))\n",
    "c = np.ones((1,4))*0.1\n",
    "w = np.ones((1,4))*0.25\n",
    "for i in range(4,len(X)):\n",
    "    m,c,w = f(X[i].reshape((1,-1)),m,c,w,np.array([0.01]),np.array([0.1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8f3ea21510>]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTCKA2p8AmZgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8f4305c390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X[:,0],X[:,1],'o')\n",
    "plt.plot(tm[:,0],tm[:,1],'o')\n",
    "\n",
    "#plt.plot(X[:20,0],X[:20,1],'o')\n",
    "plt.plot(m[0,:,0],m[0,:,1],'o')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.16262268,  0.05669099,  0.27801654,  0.50266981]], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "\n",
    "class MyRecurrentLayer(L.MergeLayer):\n",
    "    \"\"\"\n",
    "    MyRecurrentLayer(incoming, input_to_hidden,\n",
    "    hid_init=lasagne.init.Constant(0.), backwards=False,\n",
    "    learn_init=False, gradient_steps=-1, grad_clipping=0,\n",
    "    unroll_scan=False, mask_input=None,\n",
    "    only_return_final=False, **kwargs)\n",
    "    A layer which implements a recurrent connection.\n",
    "    This layer allows you to specify custom input-to-hidden\n",
    "    input-to-hidden must have 2 input layers, one with name hidden correspods to hidden parameters\n",
    "    X_n+1 = input-to-hidden(X_n,H_n)\n",
    "    Parameters\n",
    "    ----------\n",
    "    incoming : a :class:`lasagne.layers.Layer` instance or a tuple\n",
    "        The layer feeding into this layer, or the expected input shape.\n",
    "    input_to_hidden : :class:`lasagne.layers.Layer`\n",
    "        :class:`lasagne.layers.Layer` instance which connects input to the\n",
    "        hidden state (:math:`f_i`).  This layer may be connected to a chain of\n",
    "        layers, which must end in a :class:`lasagne.layers.InputLayer` with the\n",
    "        same input shape as `incoming`, except for the first dimension: When\n",
    "        ``precompute_input == True`` (the default), it must be\n",
    "        ``incoming.output_shape[0]*incoming.output_shape[1]`` or ``None``; when\n",
    "        ``precompute_input == False``, it must be ``incoming.output_shape[0]``\n",
    "        or ``None``.\n",
    "    hid_init : callable, np.ndarray, theano.shared or :class:`Layer`\n",
    "        Initializer for initial hidden state (:math:`h_0`).\n",
    "    backwards : bool\n",
    "        If True, process the sequence backwards and then reverse the\n",
    "        output again such that the output from the layer is always\n",
    "        from :math:`x_1` to :math:`x_n`.\n",
    "    learn_init : bool\n",
    "        If True, initial hidden values are learned.\n",
    "    gradient_steps : int\n",
    "        Number of timesteps to include in the backpropagated gradient.\n",
    "        If -1, backpropagate through the entire sequence.\n",
    "    grad_clipping : float\n",
    "        If nonzero, the gradient messages are clipped to the given value during\n",
    "        the backward pass.  See [1]_ (p. 6) for further explanation.\n",
    "    unroll_scan : bool\n",
    "        If True the recursion is unrolled instead of using scan. For some\n",
    "        graphs this gives a significant speed up but it might also consume\n",
    "        more memory. When `unroll_scan` is True, backpropagation always\n",
    "        includes the full sequence, so `gradient_steps` must be set to -1 and\n",
    "        the input sequence length must be known at compile time (i.e., cannot\n",
    "        be given as None).\n",
    "    mask_input : :class:`lasagne.layers.Layer`\n",
    "        Layer which allows for a sequence mask to be input, for when sequences\n",
    "        are of variable length.  Default `None`, which means no mask will be\n",
    "        supplied (i.e. all sequences are of the same length).\n",
    "    only_return_final : bool\n",
    "        If True, only return the final sequential output (e.g. for tasks where\n",
    "        a single target value for the entire sequence is desired).  In this\n",
    "        case, Theano makes an optimization which saves memory.\n",
    "    \"\"\"\n",
    "    def __init__(self, incoming, input_to_hidden, \n",
    "                 hid_init=lasagne.init.Constant(0.),\n",
    "                 backwards=False,\n",
    "                 learn_init=False,\n",
    "                 gradient_steps=-1,\n",
    "                 grad_clipping=0,\n",
    "                 unroll_scan=False,\n",
    "                 mask_input=None,\n",
    "                 only_return_final=False,\n",
    "                 **kwargs):\n",
    "\n",
    "        # This layer inherits from a MergeLayer, because it can have three\n",
    "        # inputs - the layer input, the mask and the initial hidden state.  We\n",
    "        # will just provide the layer input as incomings, unless a mask input\n",
    "        # or initial hidden state was provided.\n",
    "        incomings = [incoming]\n",
    "        self.mask_incoming_index = -1\n",
    "        self.hid_init_incoming_index = -1\n",
    "        if mask_input is not None:\n",
    "            incomings.append(mask_input)\n",
    "            self.mask_incoming_index = len(incomings)-1\n",
    "        if isinstance(hid_init, L.Layer):\n",
    "            incomings.append(hid_init)\n",
    "            self.hid_init_incoming_index = len(incomings)-1\n",
    "\n",
    "        super(MyRecurrentLayer, self).__init__(incomings, **kwargs)\n",
    "\n",
    "        input_to_hidden_in_layers = \\\n",
    "            [layer for layer in L.get_all_layers(input_to_hidden)\n",
    "             if isinstance(layer, L.InputLayer)]\n",
    "        if len(input_to_hidden_in_layers) != 2:\n",
    "            raise ValueError(\n",
    "                '`input_to_hidden` must have exactly two InputLayer, but it '\n",
    "                'has {}'.format(len(input_to_hidden_in_layers)))\n",
    "            \n",
    "        self.input_to_hidden_input = [ i for i in input_to_hidden_in_layers if i.name != 'hidden'][0]\n",
    "        self.input_to_hidden_hidden = [ i for i in input_to_hidden_in_layers if i.name == 'hidden']\n",
    "        if(len(self.input_to_hidden_hidden) != 1):\n",
    "            raise ValueError(\n",
    "                '`input_to_hidden` must have exactly one InputLayer with name hidden, but it '\n",
    "                'has {}'.format(len(self.input_to_hidden_hidden)))\n",
    "        else:\n",
    "            self.input_to_hidden_hidden = self.input_to_hidden_hidden[0]\n",
    "            \n",
    "        self.input_to_hidden = input_to_hidden\n",
    "        self.learn_init = learn_init\n",
    "        self.backwards = backwards\n",
    "        self.gradient_steps = gradient_steps\n",
    "        self.grad_clipping = grad_clipping\n",
    "        self.unroll_scan = unroll_scan\n",
    "        self.only_return_final = only_return_final\n",
    "\n",
    "        if unroll_scan and gradient_steps != -1:\n",
    "            raise ValueError(\n",
    "                \"Gradient steps must be -1 when unroll_scan is true.\")\n",
    "\n",
    "        # Retrieve the dimensionality of the incoming layer\n",
    "        input_shape = self.input_shapes[0]\n",
    "\n",
    "        if unroll_scan and input_shape[1] is None:\n",
    "            raise ValueError(\"Input sequence length cannot be specified as \"\n",
    "                             \"None when unroll_scan is True\")\n",
    "\n",
    "        \n",
    "\n",
    "        # Check that input_to_hidden and hidden_to_hidden output shapes match,\n",
    "        # but don't check a dimension if it's None for either shape\n",
    "        if not all(s1 is None or s2 is None or s1 == s2\n",
    "                   for s1, s2 in zip(input_to_hidden.output_shape[1:],\n",
    "                                     self.input_to_hidden_hidden.shape[1:])):\n",
    "            raise ValueError(\"The output shape for input_to_hidden and \"\n",
    "                             \"input shape for hidden must be equal after the first \"\n",
    "                             \"dimension, but input_to_hidden.output_shape={} \"\n",
    "                             \"and input_to_hidden_hidden.shape={}\".format(\n",
    "                                 input_to_hidden.output_shape,\n",
    "                                 self.input_to_hidden_hidden.shape))\n",
    "\n",
    "        # Initialize hidden state\n",
    "        if isinstance(hid_init, L.Layer):\n",
    "            self.hid_init = hid_init\n",
    "        else:\n",
    "            self.hid_init = self.add_param(\n",
    "                hid_init, (1,) + input_to_hidden.output_shape[1:],\n",
    "                name=\"hid_init\", trainable=learn_init, regularizable=False)\n",
    "\n",
    "    def get_params(self, **tags):\n",
    "        # Get all parameters from this layer, the master layer\n",
    "        params = super(MyRecurrentLayer, self).get_params(**tags)\n",
    "        # Combine with all parameters from the child layers\n",
    "        params += L.get_all_params(self.input_to_hidden, **tags)\n",
    "        return params\n",
    "\n",
    "    def get_output_shape_for(self, input_shapes):\n",
    "        # The shape of the input to this layer will be the first element\n",
    "        # of input_shapes, whether or not a mask input is being used.\n",
    "        input_shape = input_shapes[0]\n",
    "        # When only_return_final is true, the second (sequence step) dimension\n",
    "        # will be flattened\n",
    "        if self.only_return_final:\n",
    "            return (input_shape[0],) + self.input_to_hidden.output_shape[1:]\n",
    "        # Otherwise, the shape will be (n_batch, n_steps, trailing_dims...)\n",
    "        else:\n",
    "            return ((input_shape[0], input_shape[1]) +\n",
    "                    self.input_to_hidden.output_shape[1:])\n",
    "\n",
    "    def get_output_for(self, inputs, **kwargs):\n",
    "        \"\"\"\n",
    "        Compute this layer's output function given a symbolic input variable.\n",
    "        Parameters\n",
    "        ----------\n",
    "        inputs : list of theano.TensorType\n",
    "            `inputs[0]` should always be the symbolic input variable.  When\n",
    "            this layer has a mask input (i.e. was instantiated with\n",
    "            `mask_input != None`, indicating that the lengths of sequences in\n",
    "            each batch vary), `inputs` should have length 2, where `inputs[1]`\n",
    "            is the `mask`.  The `mask` should be supplied as a Theano variable\n",
    "            denoting whether each time step in each sequence in the batch is\n",
    "            part of the sequence or not.  `mask` should be a matrix of shape\n",
    "            ``(n_batch, n_time_steps)`` where ``mask[i, j] = 1`` when ``j <=\n",
    "            (length of sequence i)`` and ``mask[i, j] = 0`` when ``j > (length\n",
    "            of sequence i)``. When the hidden state of this layer is to be\n",
    "            pre-filled (i.e. was set to a :class:`Layer` instance) `inputs`\n",
    "            should have length at least 2, and `inputs[-1]` is the hidden state\n",
    "            to prefill with.\n",
    "        Returns\n",
    "        -------\n",
    "        layer_output : theano.TensorType\n",
    "            Symbolic output variable.\n",
    "        \"\"\"\n",
    "        # Retrieve the layer input\n",
    "        input = inputs[0]\n",
    "        # Retrieve the mask when it is supplied\n",
    "        mask = None\n",
    "        hid_init = None\n",
    "        if self.mask_incoming_index > 0:\n",
    "            mask = inputs[self.mask_incoming_index]\n",
    "        if self.hid_init_incoming_index > 0:\n",
    "            hid_init = inputs[self.hid_init_incoming_index]\n",
    "\n",
    "        # Input should be provided as (n_batch, n_time_steps, n_features)\n",
    "        # but scan requires the iterable dimension to be first\n",
    "        # So, we need to dimshuffle to (n_time_steps, n_batch, n_features)\n",
    "        input = input.dimshuffle(1, 0, *range(2, input.ndim))\n",
    "        seq_len, num_batch = input.shape[0], input.shape[1]\n",
    "\n",
    "        # When we are not precomputing the input, we also need to pass the\n",
    "        # input-to-hidden parameters to step\n",
    "        non_seqs = L.get_all_params(self.input_to_hidden)\n",
    "\n",
    "        # Create single recurrent computation step function\n",
    "        def step(input_n, hid_previous, *args):\n",
    "            hid_pre = L.get_output(\n",
    "                    self.input_to_hidden,{self.input_to_hidden_input : input_n,\n",
    "                                              self.input_to_hidden_hidden : hid_previous}, **kwargs)\n",
    "\n",
    "            # Clip gradients\n",
    "            if self.grad_clipping:\n",
    "                hid_pre = theano.gradient.grad_clip(\n",
    "                    hid_pre, -self.grad_clipping, self.grad_clipping)\n",
    "\n",
    "            return hid_pre\n",
    "\n",
    "        def step_masked(input_n, mask_n, hid_previous, *args):\n",
    "            # Skip over any input with mask 0 by copying the previous\n",
    "            # hidden state; proceed normally for any input with mask 1.\n",
    "            hid = step(input_n, hid_previous, *args)\n",
    "            hid_out = T.switch(mask_n, hid, hid_previous)\n",
    "            return [hid_out]\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask.dimshuffle(1, 0, 'x')\n",
    "            sequences = [input, mask]\n",
    "            step_fun = step_masked\n",
    "        else:\n",
    "            sequences = input\n",
    "            step_fun = step\n",
    "\n",
    "        if not isinstance(self.hid_init, L.Layer):\n",
    "            # The code below simply repeats self.hid_init num_batch times in\n",
    "            # its first dimension.  Turns out using a dot product and a\n",
    "            # dimshuffle is faster than T.repeat.\n",
    "            dot_dims = (list(range(1, self.hid_init.ndim - 1)) +\n",
    "                        [0, self.hid_init.ndim - 1])\n",
    "            hid_init = T.dot(T.ones((num_batch, 1)),\n",
    "                             self.hid_init.dimshuffle(dot_dims))\n",
    "\n",
    "        if self.unroll_scan:\n",
    "            # Retrieve the dimensionality of the incoming layer\n",
    "            input_shape = self.input_shapes[0]\n",
    "            # Explicitly unroll the recurrence instead of using scan\n",
    "            hid_out = unroll_scan(\n",
    "                fn=step_fun,\n",
    "                sequences=sequences,\n",
    "                outputs_info=[hid_init],\n",
    "                go_backwards=self.backwards,\n",
    "                non_sequences=non_seqs,\n",
    "                n_steps=input_shape[1])[0]\n",
    "        else:\n",
    "            # Scan op iterates over first dimension of input and repeatedly\n",
    "            # applies the step function\n",
    "            hid_out = theano.scan(\n",
    "                fn=step_fun,\n",
    "                sequences=sequences,\n",
    "                go_backwards=self.backwards,\n",
    "                outputs_info=[hid_init],\n",
    "                non_sequences=non_seqs,\n",
    "                truncate_gradient=self.gradient_steps,\n",
    "                strict=True)[0]\n",
    "\n",
    "        # When it is requested that we only return the final sequence step,\n",
    "        # we need to slice it out immediately after scan is applied\n",
    "        if self.only_return_final:\n",
    "            hid_out = hid_out[-1]\n",
    "        else:\n",
    "            # dimshuffle back to (n_batch, n_time_steps, n_features))\n",
    "            hid_out = hid_out.dimshuffle(1, 0, *range(2, hid_out.ndim))\n",
    "\n",
    "            # if scan is backward reverse the output\n",
    "            if self.backwards:\n",
    "                hid_out = hid_out[:, ::-1]\n",
    "\n",
    "        return hid_out\n",
    "\n",
    "    \n",
    "class InitHiddenLayer(L.Layer):\n",
    "    '''\n",
    "    input batch,samples,dims,...\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,incoming,C=lasagne.init.Constant(.1),**kwargs):\n",
    "        super(InitHiddenLayer,self).__init__(incoming,**kwargs)\n",
    "        self.C = self.add_param(C,(1,), 'C', trainable=True, regularizable=False)\n",
    "        \n",
    "    def get_output_shape_for(self,input_shape):\n",
    "        return (input_shape[:2],input_shape[2]+2)+input_shape[2+1:]\n",
    "        \n",
    "    def get_output_for(self, input, **kwargs):\n",
    "        c = T.zeros_like(input[:,:,:1,...])+self.C\n",
    "        w = T.ones_like(input[:,:,:1,...])/input.shape[1]\n",
    "        return T.concatenate([input,c,w],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from broadcast import BroadcastLayer,UnbroadcastLayer\n",
    "from utils import get_network_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_to_hidden network\n",
      "\n",
      "Layer    Description                        \n",
      "-----    -----------                        \n",
      "0        features(10, 12, 7, 11)            \n",
      "1        bcast_features(770, 12)            \n",
      "2        bcast_features_reshaped(770, 1, 12)\n",
      "3        hidden(10, 4, 14, 7, 11)           \n",
      "4        bcast_hidden(770, 4, 14)           \n",
      "5        score_gmm(770, 1)                  \n",
      "6        scored_features(770, 13)           \n",
      "7        ubcast_features(10, 13, 7, 11)     \n",
      "8        cov(10, 1, 7, 11)                  \n",
      "9        weight(10, 1, 7, 11)               \n",
      "10       featurescw(10, 14, 7, 11)          \n",
      "11       bcast_featurescw(770, 14)          \n",
      "12       update_gmm(770, 4, 14)             \n",
      "13       unbcast_hidden(10, 4, 14, 7, 11)   \n",
      "\n",
      "Layer    Description                               \n",
      "-----    -----------                               \n",
      "0        input(10, 17, 3, 7, 11)                   \n",
      "1        bcast_input(170, 3, 7, 11)                \n",
      "2        conv0(170, 12, 7, 11)                     \n",
      "3        bn0(170, 12, 7, 11)                       \n",
      "4        relu0(170, 12, 7, 11)                     \n",
      "5        conv1(170, 24, 7, 11)                     \n",
      "6        bn1(170, 24, 7, 11)                       \n",
      "7        relu1(170, 24, 7, 11)                     \n",
      "8        conv2(170, 12, 7, 11)                     \n",
      "9        bn2(170, 12, 7, 11)                       \n",
      "10       relu2(170, 12, 7, 11)                     \n",
      "11       unbcast_features(10, 17, 12, 7, 11)       \n",
      "12       features(10, 13, 12, 7, 11)               \n",
      "13       bcast_features(10010, 12)                 \n",
      "14       bcast_features_reshaped(10010, 1, 12)     \n",
      "15       init_features(10, 4, 12, 7, 11)           \n",
      "16       init_hidden((10, 4), 14, 7, 11)           \n",
      "17       recurrent_mcw(10, 13, 4, 14, 7, 11)       \n",
      "18       bcast_mcw(10010, 4, 14)                   \n",
      "19       score_gmm(10010, 1)                       \n",
      "20       scored_features(10010, 13)                \n",
      "21       unbcast_scored_features(10, 13, 13, 7, 11)\n",
      "22       bcast_features(130, 13, 7, 11)            \n",
      "23       bcast_out(130, 1, 7, 11)                  \n",
      "24       out(10, 13, 1, 7, 11)                     \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def build_cw_net(data):\n",
    "    c = L.Conv2DLayer(data,1,3,nonlinearity=lasagne.nonlinearities.softplus,name='cov',pad='same')\n",
    "    w = L.Conv2DLayer(data,1,3,nonlinearity=lasagne.nonlinearities.sigmoid,name='weight',pad='same')\n",
    "    return c,w\n",
    "    \n",
    "def build_input_to_hidden(gm_num,input_channels,features_tensor=None,hidden_tensor=None):\n",
    "    features = L.InputLayer((10,input_channels,7,11),features_tensor,name='features')\n",
    "    hidden = L.InputLayer((10,gm_num,features.output_shape[1]+2,7,11),hidden_tensor,name='hidden')\n",
    "    bcast_hidden = BroadcastLayer(hidden,(0,3,4),name='bcast_hidden')\n",
    "    bcast_features = BroadcastLayer(features,(0,2,3),name='bcast_features')\n",
    "    bcast_features_reshaped = L.reshape(bcast_features,([0],1,[1]),name='bcast_features_reshaped')\n",
    "    score = ScoreGMMLayer(bcast_features_reshaped,bcast_hidden,name='score_gmm')\n",
    "    scored_features = L.ConcatLayer([bcast_features,score],1,name='scored_features')\n",
    "    scored_features = UnbroadcastLayer(scored_features,bcast_features,name='ubcast_features')\n",
    "    cov,weight = build_cw_net(scored_features)\n",
    "    featurescw = L.ConcatLayer([features,cov,weight],1,name='featurescw')\n",
    "    bcast_featurescw = BroadcastLayer(featurescw,(0,2,3),name='bcast_featurescw')\n",
    "    update_gmm = UpdateGMMLayer(bcast_featurescw,bcast_hidden,name='update_gmm')\n",
    "    hidden = UnbroadcastLayer(update_gmm,bcast_hidden,name='unbcast_hidden')\n",
    "    return hidden\n",
    "\n",
    "\n",
    "def build_feature_net(data,input_channels,output_channels):\n",
    "    res = L.InputLayer((10,17,input_channels,7,11),data,name='input')\n",
    "    bcast = res = BroadcastLayer(res,(0,1),res,name='bcast_input')\n",
    "    for i,filters in enumerate([12,24,output_channels]):\n",
    "        res = L.Conv2DLayer(res,filters,3,nonlinearity=None,name=\"conv%d\"%i,pad='same')\n",
    "        res = L.BatchNormLayer(res,name=\"bn%d\"%i)\n",
    "        res = L.NonlinearityLayer(res,lasagne.nonlinearities.rectify,name='relu%d'%i)\n",
    "    return UnbroadcastLayer(res,bcast,name='unbcast_features')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def build_net(data,gm_num,ndim):\n",
    "    features = build_feature_net(data,3,ndim)\n",
    "    init_features = L.SliceLayer(features,slice(0,gm_num),1,name='init_features')\n",
    "    init_layer = InitHiddenLayer(init_features,name='init_hidden')\n",
    "    features = L.SliceLayer(features,slice(gm_num,None),1,name='features')\n",
    "    input_to_hiden = build_input_to_hidden(gm_num,ndim)\n",
    "    print 'input_to_hidden network'\n",
    "    print get_network_str(input_to_hiden)\n",
    "    mcw = MyRecurrentLayer(features,input_to_hiden,hid_init=init_layer,name='recurrent_mcw')\n",
    "    bcast_features = BroadcastLayer(features,(0,1,3,4),name='bcast_features')\n",
    "    bcast_features_reshaped  = L.reshape(bcast_features,([0],1,[1]),name='bcast_features_reshaped')\n",
    "    bcast_mcw = BroadcastLayer(mcw,(0,1,4,5),name='bcast_mcw')\n",
    "    score = ScoreGMMLayer(bcast_features_reshaped,bcast_mcw,name='score_gmm')\n",
    "    scored_features = L.ConcatLayer([bcast_features,score],name='scored_features')\n",
    "    unbcast_scored_features = UnbroadcastLayer(scored_features,bcast_features,name='unbcast_scored_features')\n",
    "    bcast_features = BroadcastLayer(unbcast_scored_features,(0,1),name='bcast_features')\n",
    "    bcast_out = L.Conv2DLayer(bcast_features,1,3,nonlinearity=lasagne.nonlinearities.sigmoid,name=\"bcast_out\",pad='same')\n",
    "    out = UnbroadcastLayer(bcast_out,bcast_features,name='out')    \n",
    "    return out\n",
    "    \n",
    "    \n",
    "data = T.tensor5()\n",
    "net = build_net(data,4,12) \n",
    "print get_network_str(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out = L.get_output(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict_fn = theano.function([data],out,allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = predict_fn(np.ones((10,13,3,7,11)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 9, 1, 7, 11)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
