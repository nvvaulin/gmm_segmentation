{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "from loader import PatchLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from easydict import EasyDict\n",
    "cfg = EasyDict()\n",
    "cfg.SEQ_LENGTH = 250\n",
    "cfg.TILE_SIZE = 9\n",
    "cfg.OUT_SIZE = 1\n",
    "cfg.gm_num = 4\n",
    "cfg.ndim = 4\n",
    "cfg.NAME_PREFIX = 'nt'\n",
    "cfg.NETWORK = 'conv4_net_dense'\n",
    "cfg.NAME='experiments/'+cfg.NAME_PREFIX+cfg.NETWORK+'%d'%(cfg.ndim)\n",
    "\n",
    "cfg.TRAIN = EasyDict()\n",
    "cfg.TRAIN.EPOCH = 0\n",
    "cfg.TRAIN.TRIN_EPOCH_SIZE = 1500\n",
    "cfg.TRAIN.TEST_EPOCH_SIZE = 750\n",
    "cfg.TRAIN.EPOCH_NUM = 20\n",
    "\n",
    "cfg.DATASET = EasyDict()\n",
    "cfg.DATASET.TRAIN_MINR = 0.2\n",
    "cfg.DATASET.TRAIN_MAXR = 0.3\n",
    "cfg.DATASET.TEST_MINR = 0.15\n",
    "cfg.DATASET.TEST_MAXR = 0.2\n",
    "cfg.DATASET.T_SIZE = 32\n",
    "cfg.DATASET.CASHE_SAMPLES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "train_loader = PatchLoader('data/train_%d'%cfg.DATASET.T_SIZE,\n",
    "                           cfg.DATASET.T_SIZE,\n",
    "                           cfg.SEQ_LENGTH,\n",
    "                           cfg.DATASET.TRAIN_MINR,\n",
    "                           cfg.DATASET.TRAIN_MAXR,\n",
    "                           cfg.TILE_SIZE,\n",
    "                           cfg.DATASET.CASHE_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from dataset_tools import draw\n",
    "# from loader import data_generator\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# for x,y in data_generator(train_loader,epoch_size=1,shuffle=False):\n",
    "#     print x.shape,y.shape\n",
    "#     print np.ones_like(y)[y<0.1].sum(),np.ones_like(y)[y>0.9].sum()\n",
    "#     x = np.transpose(x,(0,2,3,1)).astype(np.uint8)\n",
    "#     y = (y*255.).astype(np.uint8)\n",
    "#     _y = np.zeros(x.shape[:3],dtype=np.uint8)\n",
    "    \n",
    "#     _y[:] = y[:,0,0][:,None,None]\n",
    "#     draw(x,_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gmm_op import get_gmm,calc_log_prob_gmm\n",
    "from theano_utils import split,histogram_loss,split_tr_p_n\n",
    "import lasagne\n",
    "from networks import make_FCN\n",
    "\n",
    "\n",
    "def make_classifier(X,label,non_learn_params):\n",
    "    X = X.reshape((-1,X.shape[-1]))\n",
    "    x_tr,x_p,x_n = split_tr_p_n(X,label.flatten())\n",
    "    m,c,w = get_gmm(x_tr,\n",
    "                    gm_num = non_learn_params['gm_num'],\n",
    "                    ndims = non_learn_params['ndim'],\n",
    "                    use_approx_grad=non_learn_params['use_approx_grad'])\n",
    "    p_n = calc_log_prob_gmm(x_n,m,c,w)\n",
    "    p_p = calc_log_prob_gmm(x_p,m,c,w)\n",
    "    loss = histogram_loss(T.tanh(p_n),T.tanh(p_p),\n",
    "                          non_learn_params['min_cov'],\n",
    "                          non_learn_params['histogram_bins'],\n",
    "                          non_learn_params['width'])[0]\n",
    "    prediction = T.nnet.sigmoid(T.concatenate([p_p,p_n],axis=0))\n",
    "    Y = T.concatenate([T.ones_like(p_p),T.zeros_like(p_n)],axis=0)\n",
    "    return loss,X,Y,prediction,m,c,w,p_p,p_n\n",
    "\n",
    "def make_train(net,data,label,non_learn_params):\n",
    "    sym = L.get_output(net ,deterministic=False)\n",
    "    s = int((L.get_output_shape(net)[1]-1)/2)\n",
    "    sym = sym[:,s:s+1,s:s+1,:]\n",
    "    loss,X,Y,prediction,m,c,w,p_p,p_n = make_classifier(sym,label[:,s:s+1,s:s+1],non_learn_params)\n",
    "    params = L.get_all_params(net,trainable=True)\n",
    "    grads = T.grad(loss,params)\n",
    "    if( 'total_grad_constraint' in non_learn_params.keys()):\n",
    "        grads = lasagne.updates.total_norm_constraint(grads,non_learn_params['total_grad_constraint'])\n",
    "    updates = lasagne.updates.momentum(grads,params,\n",
    "                                       learning_rate=non_learn_params['lr'],\n",
    "                                       momentum=non_learn_params['momentum'])\n",
    "    return theano.function([data, label], [loss,X,Y,prediction,m,c,w,p_n,p_p],\\\n",
    "                               allow_input_downcast=True, updates=updates)\n",
    "\n",
    "def iterate_batches(fn,data_generator,epoch,metrix = dict(),logger=None):\n",
    "    loss=0\n",
    "    acc=0\n",
    "    labels,predicted = np.array([]),np.array([])\n",
    "    for i,batch in enumerate(data_generator()):\n",
    "        if(batch[1][:,4,4][(batch[1][:,4,4]<0.9)&(batch[1][:,4,4]>0.1)].size > len(batch[0])//4):\n",
    "            continue\n",
    "            print (\"skip\")\n",
    "        res = fn(*batch)\n",
    "        mask = (res[2]>0.9) | (res[2]<0.1)\n",
    "        loss+=res[0]\n",
    "        labels = np.concatenate((labels,res[2][mask]))\n",
    "        predicted = np.concatenate((predicted,res[3][mask]))\n",
    "    s = ' '.join(['%s=%.3f'%(k,metrix[k](labels,predicted)) for k in metrix.keys() ])\n",
    "    logger.log('epoch %i batch %i loss=%.2f l=%.2f %s\\n'%(epoch,i,loss/float(i+1),res[0],s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot create dir experiments/ntconv4_net_dense4\n",
      "[Errno 17] File exists: 'experiments/ntconv4_net_dense4'\n",
      "################### train network experiments/ntconv4_net_dense4 2018-05-02 20:07:38.495173################\n",
      "\n",
      "{'ndim': 4, 'NETWORK': 'conv4_net_dense', 'SEQ_LENGTH': 250, 'DATASET': {'TEST_MINR': 0.15, 'CASHE_SAMPLES': True, 'TRAIN_MAXR': 0.3, 'TRAIN_MINR': 0.2, 'T_SIZE': 32, 'TEST_MAXR': 0.2}, 'TRAIN': {'EPOCH': 0, 'EPOCH_NUM': 20, 'TRIN_EPOCH_SIZE': 1500, 'TEST_EPOCH_SIZE': 750}, 'gm_num': 4, 'OUT_SIZE': 1, 'TILE_SIZE': 9, 'NAME_PREFIX': 'nt', 'NAME': 'experiments/ntconv4_net_dense4'}\n",
      "cannot create dir experiments/ntconv4_net_dense4/models\n",
      "[Errno 17] File exists: 'experiments/ntconv4_net_dense4/models'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn import metrics\n",
    "import datetime\n",
    "import os\n",
    "from test_tools import make_test,GMMAlgorithm,bin_score\n",
    "from utils import Logger\n",
    "import lasagne.layers as L\n",
    "from loader import data_generator\n",
    "\n",
    "\n",
    "def update_params(epoch,params):\n",
    "    if(epoch == 4):\n",
    "        params['min_cov'].set_value(1e-8)\n",
    "        params['lr'].set_value(0.00001)          \n",
    "    if(epoch == 10):\n",
    "        params['min_cov'].set_value(1e-8)\n",
    "        params['lr'].set_value(0.000001)\n",
    "    if(epoch == 15):\n",
    "        params['lr'].set_value(0.0000001)\n",
    "        \n",
    "try:\n",
    "    os.mkdir(cfg.NAME)\n",
    "except Exception as e:\n",
    "    print 'cannot create dir %s'%(cfg.NAME)\n",
    "    print e\n",
    "\n",
    "logger =Logger('std',cfg.NAME+\"/train.log\")\n",
    "\n",
    "logger.log('################### train network '+cfg.NAME+ ' ' + str(datetime.datetime.now())+'################\\n')    \n",
    "logger.log(str(cfg))\n",
    "\n",
    "try:\n",
    "    os.mkdir('%s/models'%(cfg.NAME))\n",
    "except Exception as e:\n",
    "    logger.log('cannot create dir %s/models'%(cfg.NAME))\n",
    "    print e\n",
    "    \n",
    "metrix = {'aps' : average_precision_score,\n",
    "              'f1' : lambda y,s : metrics.f1_score(y,bin_score(s)),\n",
    "              'acc' : lambda y,s : metrics.accuracy_score(y,bin_score(s))}\n",
    "\n",
    "non_learn_params={'min_cov' : theano.shared(1e-3),\n",
    "                  'lr' : theano.shared(np.array(1e-2, dtype=theano.config.floatX)),\n",
    "                  'width': theano.shared(4.),\n",
    "                  'total_grad_constraint': 10,\n",
    "                  'histogram_bins' : 100,\n",
    "                  'use_approx_grad' : True,\n",
    "                  'ndim' : cfg.ndim,\n",
    "                  'gm_num' : cfg.gm_num,\n",
    "                  'momentum' : theano.shared(np.array(0.9, dtype=theano.config.floatX))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load finction conv4_net_dense\n",
      "\n",
      "In -->     Layer    --> Out    Description                \n",
      "-------    -----    -------    -----------                \n",
      "[]         0        [1]        data(None, 3, 9, 9)        \n",
      "[0]        1        [2]        conv_1(None, 6, 9, 9)      \n",
      "[1]        2        [3]        bn_1(None, 6, 9, 9)        \n",
      "[2]        3        [4]        relu_1(None, 6, 9, 9)      \n",
      "[3]        4        [5]        conv_2(None, 12, 9, 9)     \n",
      "[4]        5        [6]        bn_2(None, 12, 9, 9)       \n",
      "[5]        6        [7]        relu_2(None, 12, 9, 9)     \n",
      "[6]        7        [8]        conv_3(None, 24, 9, 9)     \n",
      "[7]        8        [9]        bn_3(None, 24, 9, 9)       \n",
      "[8]        9        [10]       relu_3(None, 24, 9, 9)     \n",
      "[9]        10       [11]       conv_4(None, 3, 9, 9)      \n",
      "[10]       11       [12]       transpose(None, 9, 9, 3)   \n",
      "[11]       12       [13]       l2norm(None, 9, 9, 4)      \n",
      "[12]       13       []         normed_dense(None, 9, 9, 4)\n",
      "train_fn compiled\n"
     ]
    }
   ],
   "source": [
    "data = T.tensor4(name='data')\n",
    "label = T.tensor3(name='label')\n",
    "net = make_FCN(cfg.NETWORK,data,\n",
    "               ndim=cfg.ndim,\n",
    "               model_name='%s/models/%03d'%(cfg.NAME,cfg.TRAIN.EPOCH) if cfg.TRAIN.EPOCH > 0 else '',\n",
    "               input_shape = (None,3,cfg.TILE_SIZE,cfg.TILE_SIZE),\n",
    "               pad = 'same',\n",
    "               logger=logger)\n",
    "train_fn = make_train(net,data,label,non_learn_params)\n",
    "logger.log('train_fn compiled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "globalPool = Pool(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "non_learn_params['lr'].set_value(0.001)\n",
    "#non_learn_params['beta1'].set_value(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch 0 batch 1186 loss=896682.87 l=14072894.83 acc=0.766 aps=0.762 f1=0.842\n",
      "\n",
      "checkpoint experiments/ntconv4_net_dense4/models/000.npz\n",
      "train\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-2e8e9696ad1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     iterate_batches(train_fn,                    lambda : data_generator(train_loader,epoch_size=10000000,shuffle=True),\n\u001b[0;32m---> 34\u001b[0;31m                    j,metrix,logger = logger)\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'%s/models/%03d'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m20\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-1f12bd96360e>\u001b[0m in \u001b[0;36miterate_batches\u001b[0;34m(fn, data_generator, epoch, metrix, logger)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0macc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nvaullin/gmm_segmentation/loader.pyc\u001b[0m in \u001b[0;36mdata_generator\u001b[0;34m(gmm_loader, epoch_size, shuffle)\u001b[0m\n\u001b[1;32m    244\u001b[0m                    \u001b[0mepoch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m                    shuffle=False):\n\u001b[0;32m--> 246\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgmm_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mepoch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nvaullin/gmm_segmentation/loader.pyc\u001b[0m in \u001b[0;36miterate\u001b[0;34m(self, shuffle)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpatch_inx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimg_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0minx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpatch_inx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mpatches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch_inx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatches\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nvaullin/gmm_segmentation/loader.pyc\u001b[0m in \u001b[0;36mload_sample\u001b[0;34m(self, patch_inx, inx)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0mpatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_l\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_l\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_l\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         patches, mask, names = self.balance_patch(patch_inx, patches, mask, x + self.out_size // 2,\n\u001b[0;32m--> 225\u001b[0;31m                                                 y + self.out_size // 2, names)\n\u001b[0m\u001b[1;32m    226\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatches\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nvaullin/gmm_segmentation/loader.pyc\u001b[0m in \u001b[0;36mbalance_patch\u001b[0;34m(self, patch_inx, patches, mask, x, y, names)\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mm_patch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_motion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch_inx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m             \u001b[0mm_patch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm_patch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m240\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mm_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m240\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nvaullin/gmm_segmentation/loader.pyc\u001b[0m in \u001b[0;36mload_motion\u001b[0;34m(self, patch_inx)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_motion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_inx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0mpatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmotions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpatch_inx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmotion_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpatch_inx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mpatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nvaullin/gmm_segmentation/loader.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, path, cashe)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcashe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcashe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0mpatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcashed_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mpatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nvaullin/gmm_segmentation/loader.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_UNCHANGED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCV_LOAD_IMAGE_UNCHANGED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from utils import save_weights\n",
    "\n",
    "def gen_FCN(network,model,ndim):\n",
    "    def res(data,input_shape):\n",
    "        net = make_FCN(network,data,\n",
    "                       ndim=ndim,\n",
    "                       model_name=model,\n",
    "                       input_shape = input_shape,\n",
    "                       pad = 'same')\n",
    "        return L.get_output(net)\n",
    "    return res\n",
    "\n",
    "for j in range(cfg.TRAIN.EPOCH):\n",
    "    update_params(j,non_learn_params)\n",
    "\n",
    "# logger.log('test')\n",
    "# test_algorithm = GMMAlgorithm(gen_FCN(cfg.NETWORK,'',cfg.ndim),\n",
    "#                                cfg.gm_num,\n",
    "#                                globalPool)\n",
    "# result = make_test(test_algorithm,\n",
    "#       out_dir=None,\n",
    "#       dataset='data/test',\n",
    "#       train_size = 100,\n",
    "#       test_size=100,\n",
    "#       im_size = (240//2,320//2),\n",
    "#       metrics = metrix,\n",
    "#       logger=logger,\n",
    "#       only_with_motion = True)\n",
    "\n",
    "for j in range(cfg.TRAIN.EPOCH,cfg.TRAIN.EPOCH_NUM):\n",
    "    update_params(j,non_learn_params)\n",
    "    logger.log('train')\n",
    "    iterate_batches(train_fn,\\\n",
    "                    lambda : data_generator(train_loader,epoch_size=10000000,shuffle=True),\n",
    "                   j,metrix,logger = logger)\n",
    "    save_weights(net,'%s/models/%03d'%(cfg.NAME,j))\n",
    "    if((j+1)%20 == 0):\n",
    "        logger.log('test')\n",
    "        test_algorithm = GMMAlgorithm(gen_FCN(cfg.NETWORK,'%s/models/%03d'%(cfg.NAME,j),cfg.ndim),\n",
    "                                       cfg.gm_num,\n",
    "                                       globalPool)\n",
    "        result = make_test(test_algorithm,\n",
    "              out_dir=None,\n",
    "              dataset='data/test',\n",
    "              train_size = 100,\n",
    "              test_size=100,\n",
    "              im_size = (240//2,320//2),\n",
    "              metrics = metrix,\n",
    "              logger=logger,\n",
    "              only_with_motion = True)\n",
    "\n",
    "\n",
    "logger.log('################### done #######################\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i,batch in enumerate(data_generator(test_loader,epoch_size=100,shuffle=False)):\n",
    "    res = test_fn(*batch)\n",
    "    if(i == 0):\n",
    "        p =res[-1]\n",
    "        n = res[-2]\n",
    "    p = np.concatenate((p,res[-1]))\n",
    "    n = np.concatenate((n,res[-2]))\n",
    "plt.hist(np.clip(res[-1],-10,100),100,normed=True,label='positive')\n",
    "plt.hist(np.clip(res[-2],-10,100),100,normed=True,label='negative')\n",
    "plt.legend()\n",
    "plt.show()  \n",
    "plt.hist(np.clip(p,-20,100),100,normed=True,label='positive')\n",
    "plt.hist(np.clip(n,-20,100),100,normed=True,label='negative')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
