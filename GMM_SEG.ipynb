{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 5105 on context None\n",
      "Mapped name None to device cuda0: GeForce GTX TITAN X (0000:05:00.0)\n"
     ]
    }
   ],
   "source": [
    "import theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from easydict import EasyDict\n",
    "cfg = EasyDict()\n",
    "cfg.SEQ_LENGTH = 250\n",
    "cfg.TILE_SIZE = 9\n",
    "cfg.OUT_SIZE = 1\n",
    "cfg.TRAIN = EasyDict()\n",
    "cfg.TRAIN.EPOCH = 0\n",
    "cfg.TRAIN.EPOCH_SIZE = 1000\n",
    "cfg.TRAIN.EPOCH_NUM = 10\n",
    "cfg.gm_num = 4\n",
    "cfg.ndim = 12\n",
    "cfg.NAME = 'conv_ndim%i'%(cfg.ndim)#'conv_net_no_bn_ndim12010'#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 2] No such file or directory: '/media/hpc2_storage/nvaulin/ties32'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-76dd235b3f1d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mloader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTieLoader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m train_loader = TieLoader('/media/hpc2_storage/nvaulin/ties32',\n\u001b[1;32m----> 3\u001b[1;33m                          0.2,0.3,t_size=64,mask_size=cfg.OUT_SIZE,sample_size=cfg.TILE_SIZE,cache_samples=True)\n\u001b[0m\u001b[0;32m      4\u001b[0m test_loader = TieLoader('/media/hpc2_storage/nvaulin/test_ties32',\n\u001b[0;32m      5\u001b[0m                         0.2,0.3,t_size=64,mask_size=cfg.OUT_SIZE,sample_size=cfg.TILE_SIZE,cache_samples=True)\n",
      "\u001b[1;32m/home/nvaullin/gmm_segmentation/loader.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, min_r, max_r, t_size, sample_size, mask_size, cache_samples)\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmotion_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterate_folders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_list\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'input.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'input.jpg'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmotion_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmotion_list\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'motion.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'motion.jpg'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/nvaullin/gmm_segmentation/dataset_tools.pyc\u001b[0m in \u001b[0;36miterate_folders\u001b[1;34m(dataset, out_dir)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0miterate_folders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mout_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0msubsets\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0msubsets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 2] No such file or directory: '/media/hpc2_storage/nvaulin/ties32'"
     ]
    }
   ],
   "source": [
    "from loader import TieLoader,data_generator\n",
    "train_loader = TieLoader('/media/hpc2_storage/nvaulin/ties32',\n",
    "                         0.2,0.3,t_size=64,mask_size=cfg.OUT_SIZE,sample_size=cfg.TILE_SIZE,cache_samples=True)\n",
    "test_loader = TieLoader('/media/hpc2_storage/nvaulin/test_ties32',\n",
    "                        0.2,0.3,t_size=64,mask_size=cfg.OUT_SIZE,sample_size=cfg.TILE_SIZE,cache_samples=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from dataset_tools import draw\n",
    "\n",
    "# for x,y in data_generator(train_loader,epoch_size=1,shuffle=True):\n",
    "#     print x.shape\n",
    "#     print np.ones_like(y)[y<0.1].sum(),np.ones_like(y)[y>0.9].sum()\n",
    "#     x = np.transpose(x,(0,2,3,1)).astype(np.uint8)\n",
    "#     y = (y*255.).astype(np.uint8)\n",
    "#     _y = np.zeros(x.shape[:3],dtype=np.uint8)\n",
    "#     _y[:] = y[:,0,0][:,None,None]\n",
    "#     draw(x,_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano.tensor as T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from lasagne.layers import (InputLayer, ConcatLayer, Pool2DLayer, ReshapeLayer, DimshuffleLayer, NonlinearityLayer,\n",
    "                            DropoutLayer, Deconv2DLayer, batch_norm)\n",
    "\n",
    "from lasagne.layers import Conv2DLayer as ConvLayer\n",
    "import lasagne\n",
    "from lasagne.init import HeNormal\n",
    "\n",
    "\n",
    "def build_UNet(input_l, num_output_classes=2, pad='same', nonlinearity=lasagne.nonlinearities.elu, base_n_filters=16):\n",
    "    net = OrderedDict()\n",
    "    net['input'] = input_l\n",
    "\n",
    "    net['contr_1_1'] = batch_norm(ConvLayer(net['input'], base_n_filters, 3, nonlinearity=nonlinearity, pad=pad, W=HeNormal(gain=\"relu\")))\n",
    "    net['contr_1_2'] = batch_norm(ConvLayer(net['contr_1_1'], base_n_filters, 3, nonlinearity=nonlinearity, pad=pad, W=HeNormal(gain=\"relu\")))\n",
    "    net['pool1'] = Pool2DLayer(net['contr_1_2'], 2)\n",
    "\n",
    "    net['contr_2_1'] = batch_norm(ConvLayer(net['pool1'], base_n_filters*2, 3, nonlinearity=nonlinearity, pad=pad, W=HeNormal(gain=\"relu\")))\n",
    "    net['contr_2_2'] = batch_norm(ConvLayer(net['contr_2_1'], base_n_filters*2, 3, nonlinearity=nonlinearity, pad=pad, W=HeNormal(gain=\"relu\")))\n",
    "    net['pool2'] = Pool2DLayer(net['contr_2_2'], 2)\n",
    "\n",
    "    net['contr_3_1'] = batch_norm(ConvLayer(net['pool2'], base_n_filters*4, 3, nonlinearity=nonlinearity, pad=pad, W=HeNormal(gain=\"relu\")))\n",
    "    net['contr_3_2'] = batch_norm(ConvLayer(net['contr_3_1'], base_n_filters*4, 3, nonlinearity=nonlinearity, pad=pad, W=HeNormal(gain=\"relu\")))\n",
    "    net['pool3'] = Pool2DLayer(net['contr_3_2'], 2)\n",
    "\n",
    "    net['contr_4_1'] = batch_norm(ConvLayer(net['pool3'], base_n_filters*8, 3, nonlinearity=nonlinearity, pad=pad, W=HeNormal(gain=\"relu\")))\n",
    "    net['contr_4_2'] = batch_norm(ConvLayer(net['contr_4_1'], base_n_filters*8, 3, nonlinearity=nonlinearity, pad=pad, W=HeNormal(gain=\"relu\")))\n",
    "    l = net['pool4'] = Pool2DLayer(net['contr_4_2'], 2)\n",
    "\n",
    "    net['encode_1'] = batch_norm(ConvLayer(l, base_n_filters*16, 3, nonlinearity=nonlinearity, pad=pad, W=HeNormal(gain=\"relu\")))\n",
    "    net['encode_2'] = batch_norm(ConvLayer(net['encode_1'], base_n_filters*16, 3, nonlinearity=nonlinearity, pad=pad, W=HeNormal(gain=\"relu\")))\n",
    "    net['upscale1'] = batch_norm(Deconv2DLayer(net['encode_2'], base_n_filters*16, 2, 2, crop=\"valid\", nonlinearity=nonlinearity, W=HeNormal(gain=\"relu\")))\n",
    "\n",
    "    net['concat1'] = ConcatLayer([net['upscale1'], net['contr_4_2']], cropping=(None, None, \"center\", \"center\"))\n",
    "    net['expand_1_1'] = batch_norm(ConvLayer(net['concat1'], base_n_filters*8, 3, nonlinearity=nonlinearity, pad=pad, W=HeNormal(gain=\"relu\")))\n",
    "    net['expand_1_2'] = batch_norm(ConvLayer(net['expand_1_1'], base_n_filters*8, 3, nonlinearity=nonlinearity, pad=pad, W=HeNormal(gain=\"relu\")))\n",
    "    net['upscale2'] = batch_norm(Deconv2DLayer(net['expand_1_2'], base_n_filters*8, 2, 2, crop=\"valid\", nonlinearity=nonlinearity, W=HeNormal(gain=\"relu\")))\n",
    "\n",
    "    net['concat2'] = ConcatLayer([net['upscale2'], net['contr_3_2']], cropping=(None, None, \"center\", \"center\"))\n",
    "    net['expand_2_1'] = batch_norm(ConvLayer(net['concat2'], base_n_filters*4, 3, nonlinearity=nonlinearity, pad=pad, W=HeNormal(gain=\"relu\")))\n",
    "    net['expand_2_2'] = batch_norm(ConvLayer(net['expand_2_1'], base_n_filters*4, 3, nonlinearity=nonlinearity, pad=pad, W=HeNormal(gain=\"relu\")))\n",
    "    net['upscale3'] = batch_norm(Deconv2DLayer(net['expand_2_2'], base_n_filters*4, 2, 2, crop=\"valid\", nonlinearity=nonlinearity, W=HeNormal(gain=\"relu\")))\n",
    "\n",
    "    net['concat3'] = ConcatLayer([net['upscale3'], net['contr_2_2']], cropping=(None, None, \"center\", \"center\"))\n",
    "    net['expand_3_1'] = batch_norm(ConvLayer(net['concat3'], base_n_filters*2, 3, nonlinearity=nonlinearity, pad=pad, W=HeNormal(gain=\"relu\")))\n",
    "    net['expand_3_2'] = batch_norm(ConvLayer(net['expand_3_1'], base_n_filters*2, 3, nonlinearity=nonlinearity, pad=pad, W=HeNormal(gain=\"relu\")))\n",
    "    net['upscale4'] = batch_norm(Deconv2DLayer(net['expand_3_2'], base_n_filters*2, 2, 2, crop=\"valid\", nonlinearity=nonlinearity, W=HeNormal(gain=\"relu\")))\n",
    "\n",
    "    net['concat4'] = ConcatLayer([net['upscale4'], net['contr_1_2']], cropping=(None, None, \"center\", \"center\"))\n",
    "    net['expand_4_1'] = batch_norm(ConvLayer(net['concat4'], base_n_filters, 3, nonlinearity=nonlinearity, pad=pad, W=HeNormal(gain=\"relu\")))\n",
    "    net['expand_4_2'] = batch_norm(ConvLayer(net['expand_4_1'], base_n_filters, 3, nonlinearity=nonlinearity, pad=pad, W=HeNormal(gain=\"relu\")))\n",
    "\n",
    "    net['output_segmentation'] = ConvLayer(net['expand_4_2'], num_output_classes, 1, nonlinearity=None)\n",
    "    return net['output_segmentation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In -->     Layer    --> Out    Description              \n",
      "-------    -----    -------    -----------              \n",
      "[]         0        [1]        data(None, 3, 9, 9)      \n",
      "[0]        1        [2]        conv_1(None, 6, 7, 7)    \n",
      "[1]        2        [3]        bn_1(None, 6, 7, 7)      \n",
      "[2]        3        [4]        relu_1(None, 6, 7, 7)    \n",
      "[3]        4        [5]        conv_2(None, 12, 5, 5)   \n",
      "[4]        5        [6]        bn_2(None, 12, 5, 5)     \n",
      "[5]        6        [7]        relu_2(None, 12, 5, 5)   \n",
      "[6]        7        [8]        conv_3(None, 24, 3, 3)   \n",
      "[7]        8        [9]        bn_3(None, 24, 3, 3)     \n",
      "[8]        9        [10]       relu_3(None, 24, 3, 3)   \n",
      "[9]        10       [11]       conv_4(None, 11, 1, 1)   \n",
      "[10]       11       [12]       transpose(None, 1, 1, 11)\n",
      "[11]       12       []         l2norm(None, 1, 1, 12)   \n"
     ]
    }
   ],
   "source": [
    "from lasagne import layers as L\n",
    "from lasagne.nonlinearities import rectify,softmax\n",
    "from utils import NormedDense,L2NormLayer\n",
    "from utils import get_network_str,save_weights,load_weights\n",
    "import lasagne\n",
    "\n",
    "\n",
    "def conv(data,num_filters,name,pad):\n",
    "    return L.Conv2DLayer(data,filter_size=(3,3),num_filters=num_filters,\n",
    "                        nonlinearity=None,pad=pad,\n",
    "                        name='conv_'+name) \n",
    "\n",
    "def conv_nonl(data,num_filters,name,pad):\n",
    "    res = conv(data,num_filters,name,pad=pad)\n",
    "    res = L.BatchNormLayer(res,name='bn_'+name,alpha=0.05)\n",
    "    res = L.NonlinearityLayer(res,rectify,name='relu_'+name) \n",
    "    return res\n",
    "\n",
    "def FCN(data,ndim,verbose=True,model_name='',input_shape = (None,3,None,None),pad='same'):\n",
    "    datal = res = L.InputLayer(input_shape\n",
    "                           ,data/256.\n",
    "                           ,name='data')\n",
    "    #res = build_UNet(datal,ndim-1)\n",
    "    res = conv_nonl(res,6,'1',pad= pad)\n",
    "    res = conv_nonl(res,12,'2',pad=pad)\n",
    "    res = conv_nonl(res,24,'3',pad=pad)\n",
    "    res = conv(res,cfg.ndim-1,'4',pad=pad)\n",
    "    res = L.DimshuffleLayer(res,(0,2,3,1),name='transpose')\n",
    "    res = L2NormLayer(res,1e-8,name='l2norm')\n",
    "    if(model_name!=''):\n",
    "        load_weights(res,'models/'+model_name)\n",
    "    print get_network_str(res,incomings=True,outgoings=True)\n",
    "    return res\n",
    "        \n",
    "def soft_predict_sym(features,means,covars,weights):\n",
    "    return 1.-T.nnet.sigmoid(calc_log_prob_gmm(features,means,covars,weights))\n",
    "\n",
    "data = T.tensor4(name='data')\n",
    "label = T.tensor3(name='label')\n",
    "net = FCN(data,ndim=cfg.ndim,model_name='',input_shape = (None,3,cfg.TILE_SIZE,cfg.TILE_SIZE),pad = 'valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/lasagne/layers/helper.py:212: UserWarning: get_output() was called with unused kwargs:\n",
      "\tdetermenisic (perhaps you meant deterministic)\n",
      "  % \"\\n\\t\".join(suggestions))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_fn compiled\n",
      "test_fn compiled\n"
     ]
    }
   ],
   "source": [
    "from gmm_op import get_gmm,calc_log_prob_gmm\n",
    "from theano_utils import split,histogram_loss\n",
    "\n",
    "def split_tr_p_n(x,y):\n",
    "    x_tr_p,x_n = split(x,y)\n",
    "    x_p = x_tr_p[x_tr_p.shape[0]//2:]\n",
    "    x_tr = x_tr_p[:x_tr_p.shape[0]//2]\n",
    "    return x_tr,x_p,x_n\n",
    "\n",
    "def make_classifier(X,label,non_learn_params):\n",
    "    X = X.reshape((-1,X.shape[-1]))\n",
    "    x_tr,x_p,x_n = split_tr_p_n(X,label.flatten())\n",
    "    m,c,w = get_gmm(x_tr,cfg.gm_num,cfg.ndim,use_approx_grad=True)\n",
    "    p_n = calc_log_prob_gmm(x_n,m,c,w)\n",
    "    p_p = calc_log_prob_gmm(x_p,m,c,w)\n",
    "#     loss = histogram_loss(p_n,p_p,\n",
    "#                           non_learn_params['min_cov'],\n",
    "#                           100,\n",
    "#                           non_learn_params['width'])[0]\n",
    "    width = non_learn_params['width']\n",
    "    loss = T.max(T.concatenate([T.zeros_like(p_p).reshape((-1,1)),(width-p_p).reshape((-1,1))],axis=1),axis=1).mean()+\\\n",
    "           T.max(T.concatenate([T.zeros_like(p_n).reshape((-1,1)),(width+p_n).reshape((-1,1))],axis=1),axis=1).mean()\n",
    "    prediction = T.nnet.sigmoid(T.concatenate([p_p,p_n],axis=0))\n",
    "    Y = T.concatenate([T.ones_like(p_p),T.zeros_like(p_n)],axis=0)\n",
    "    return loss,X,Y,prediction,m,c,w,p_p,p_n\n",
    "\n",
    "def make_train(net,data,label,non_learn_params):\n",
    "    sym = L.get_output(net ,determenisic=False)\n",
    "    #s = int((L.get_output_shape(net)[1]-1)/2)\n",
    "    #sym = sym[:,s:s+1,s:s+1,:]\n",
    "    loss,X,Y,prediction,m,c,w,p_p,p_n = make_classifier(sym,label,non_learn_params)\n",
    "    params = L.get_all_params(net,trainable=True)\n",
    "    updates = lasagne.updates.adam(loss,params,non_learn_params['lr'])\n",
    "    return theano.function([data, label], [loss,X,Y,prediction,m,c,w],\\\n",
    "                               allow_input_downcast=True, updates=updates)\n",
    "\n",
    "\n",
    "def make_test(net,data,label,non_learn_params):\n",
    "    sym = L.get_output(net ,determenisic=True)\n",
    "    #s = int((L.get_output_shape(net)[1]-1)/2)\n",
    "    #sym = sym[:,s:s+1,s:s+1]\n",
    "    loss,X,Y,prediction,m,c,w,p_p,p_n = make_classifier(sym,label,non_learn_params)\n",
    "    return theano.function([data, label], [loss,X,Y,prediction,m,c,w],\\\n",
    "                               allow_input_downcast=True)\n",
    "        \n",
    "\n",
    "non_learn_params={'min_cov' : theano.shared(1e-3),\n",
    "                  'lr' : theano.shared(np.array(1e-2, dtype=theano.config.floatX)),\n",
    "                  'width': theano.shared(1.)}\n",
    "\n",
    "train_fn = make_train(net,data,label,non_learn_params)\n",
    "print 'train_fn compiled'\n",
    "test_fn = make_test(net,data,label,non_learn_params)\n",
    "print 'test_fn compiled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint models/conv_ndim12000.npz\n",
      "train\n",
      " epoch 0 batch 1499 loss=12.31 l=4.00 aps=0.966 pp=0.925 pn=0.795 int_pp_pn=0.935     \n",
      "checkpoint models/conv_ndim12000.npz\n",
      "test\n",
      " epoch 0 batch 749 loss=826.44 l=9.11 aps=0.944 pp=0.880 pn=0.763 int_pp_pn=0.888     \n",
      "train\n",
      " epoch 1 batch 1499 loss=9.55 l=22.74 aps=0.973 pp=0.916 pn=0.848 int_pp_pn=0.949     \n",
      "checkpoint models/conv_ndim12001.npz\n",
      "test\n",
      " epoch 1 batch 749 loss=780.72 l=0.34 aps=0.933 pp=0.811 pn=0.800 int_pp_pn=0.878     \n",
      "train\n",
      " epoch 2 batch 1499 loss=10.41 l=7.40 aps=0.977 pp=0.930 pn=0.857 int_pp_pn=0.955     \n",
      "checkpoint models/conv_ndim12002.npz\n",
      "test\n",
      " epoch 2 batch 749 loss=681.68 l=0.00 aps=0.921 pp=0.808 pn=0.848 int_pp_pn=0.854     \n",
      "train\n",
      " epoch 3 batch 1499 loss=11.66 l=8.72 aps=0.966 pp=0.901 pn=0.894 int_pp_pn=0.940     \n",
      "checkpoint models/conv_ndim12003.npz\n",
      "test\n",
      " epoch 3 batch 749 loss=326.08 l=11.19 aps=0.913 pp=0.776 pn=0.864 int_pp_pn=0.845     \n",
      "train\n",
      " epoch 4 batch 1499 loss=12.82 l=2.58 aps=0.967 pp=0.892 pn=0.893 int_pp_pn=0.941     \n",
      "checkpoint models/conv_ndim12004.npz\n",
      "test\n",
      " epoch 4 batch 749 loss=669.73 l=4.17 aps=0.920 pp=0.686 pn=0.842 int_pp_pn=0.853     \n",
      "train\n",
      " epoch 5 batch 1499 loss=10.41 l=0.00 aps=0.970 pp=0.903 pn=0.892 int_pp_pn=0.945     \n",
      "checkpoint models/conv_ndim12005.npz\n",
      "test\n",
      " epoch 5 batch 749 loss=249.60 l=0.00 aps=0.919 pp=0.801 pn=0.887 int_pp_pn=0.846     \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "import datetime\n",
    "\n",
    "fout = open(\"out.txt\",'a')\n",
    "fout.write(str(datetime.datetime.now())+'\\n')\n",
    "def get_pp_pn(l,pred):\n",
    "    o = np.ones(len(l))\n",
    "    pn = []\n",
    "    pp = []\n",
    "    R = pred[::max(len(pred)//100,1)].copy()\n",
    "    R  = np.sort(R)\n",
    "    for r in R:\n",
    "        pn.append(o[(pred > r)&(l>0.9)].sum()/o[l>0.9].sum())\n",
    "        pp.append(o[(pred < r)&(l<0.1)].sum()/o[l<0.1].sum())\n",
    "    pp,pn = np.array(pp),np.array(pn)\n",
    "    return (np.abs(pn[1:]-pn[:-1])*(pp[1:]+pp[:-1])/2.).sum()\n",
    "\n",
    "def iterate_batches(fn,data_generator,epoch,metrix = dict()):\n",
    "    loss=0\n",
    "    acc=0\n",
    "    labels,predicted = np.array([]),np.array([])\n",
    "    for i,batch in enumerate(data_generator()):\n",
    "        res = fn(*batch)\n",
    "        fout.write(\"error \"+str(batch[0].shape)+ ' '+str(batch[1].shape)+'\\n')\n",
    "        mask = (res[2]>0.9) | (res[2]<0.1)\n",
    "        loss+=res[0]\n",
    "        labels = np.concatenate((labels,res[2][mask]))\n",
    "        predicted = np.concatenate((predicted,res[3][mask]))\n",
    "        s = ' '.join(['%s=%.3f'%(k,metrix[k](labels,predicted)) for k in metrix.keys() ])\n",
    "#         if(i%100 == 0):\n",
    "#             print '\\r epoch %i batch %i loss=%.2f l=%.2f %s     '%\\\n",
    "#             (epoch,i,loss/float(i+1),res[0],s)\n",
    "#             sys.stdout.flush()        \n",
    "#             fout.write('epoch %i batch %i loss=%.2f l=%.2f %s\\n'%(epoch,i,loss/float(i+1),res[0],s))\n",
    "#             fout.flush()\n",
    "    s = ' '.join(['%s=%.3f'%(k,metrix[k](labels,predicted)) for k in metrix.keys() ])\n",
    "    print '\\r epoch %i batch %i loss=%.2f l=%.2f %s     '%\\\n",
    "    (epoch,i,loss/float(i+1),res[0],s)\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    fout.write('epoch %i batch %i loss=%.2f l=%.2f %s\\n'%(epoch,i,loss/float(i+1),res[0],s))\n",
    "    fout.flush()\n",
    "\n",
    "metrix = { 'aps' : average_precision_score,\n",
    "           'pp'  : lambda l,pred : np.ones(len(l))[(pred < 0.5)&(l<0.1)].sum()/np.ones(len(l))[l<0.1].sum(),\n",
    "           'pn'  : lambda l,pred : np.ones(len(l))[(pred >= .5)&(l>0.9)].sum()/np.ones(len(l))[l>0.9].sum(),\n",
    "           'int_pp_pn' : lambda l,pred : get_pp_pn(l,pred)}\n",
    "\n",
    "def update_params(epoch,params):\n",
    "    if(epoch == 0):\n",
    "        params['min_cov'].set_value(1e-8)\n",
    "        #params['p_n_weight'].set_value(1e1)\n",
    "        params['lr'].set_value(1e-3)\n",
    "    \n",
    "def fit(name,\n",
    "        net,\n",
    "        train_fn,test_fn,\n",
    "        train_loader,test_loader,\n",
    "        non_learn_params,\n",
    "        epochs=3,train_esize=1500,test_esize=750,\n",
    "        metrix = metrix,update_params = update_params):\n",
    "    save_weights(net,'models/%s%03d'%(name,0))\n",
    "    for j in range(0,epochs):\n",
    "        update_params(j,non_learn_params)\n",
    "        print('train')\n",
    "        fout.write('train')\n",
    "        fout.flush()\n",
    "        sys.stdout.flush()\n",
    "        iterate_batches(train_fn,\\\n",
    "                        lambda : data_generator(train_loader,epoch_size=train_esize,shuffle=True),\n",
    "                       j,metrix)\n",
    "        save_weights(net,'models/%s%03d'%(name,j))\n",
    "        print('test')\n",
    "        fout.write('test')\n",
    "        fout.flush()\n",
    "        sys.stdout.flush()\n",
    "        iterate_batches(test_fn,\\\n",
    "                        lambda : data_generator(test_loader,epoch_size=test_esize,shuffle=True),\n",
    "                       j,metrix)\n",
    "\n",
    "        \n",
    "# iterate_batches(test_fn,\\\n",
    "#             lambda : data_generator(test_loader,epoch_size=750,shuffle=True),\n",
    "#           -1,metrix)\n",
    "fit(cfg.NAME,net,train_fn,test_fn,train_loader,test_loader,non_learn_params,epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "non_learn_params['width'].set_value(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i,batch in enumerate(data_generator(test_loader,epoch_size=100,shuffle=False)):\n",
    "    res = test_fn(*batch)\n",
    "    if(i == 0):\n",
    "        p =res[-1]\n",
    "        n = res[-2]\n",
    "    p = np.concatenate((p,res[-1]))\n",
    "    n = np.concatenate((n,res[-2]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npOYMvSQ1Z+glqTlDL0nN/S8CrwQUgiLMlgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa81b0c1310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.clip(res[-1],-10,100),100,normed=True)\n",
    "plt.hist(np.clip(res[-2],-10,100),100,normed=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa8193d2450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.clip(p,-20,100),100,normed=True)\n",
    "plt.hist(np.clip(n,-20,100),100,normed=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In -->     Layer    --> Out    Description           \n",
      "-------    -----    -------    -----------           \n",
      "[]         0        [1]        data(250, 3, 16, 16)  \n",
      "[0]        1        [2]        bn0(250, 3, 16, 16)   \n",
      "[1]        2        [3]        conv1(250, 12, 16, 16)\n",
      "[2]        3        [4]        bn1(250, 12, 16, 16)  \n",
      "[3]        4        [5]        nonl1(250, 12, 16, 16)\n",
      "[4]        5        [6]        conv2(250, 24, 16, 16)\n",
      "[5]        6        [7]        bn2(250, 24, 16, 16)  \n",
      "[6]        7        [8]        nonl2(250, 24, 16, 16)\n",
      "[7]        8        [9]        3(250, 3, 16, 16)     \n",
      "[8]        9        []         3(250, 3, 16, 16)     \n"
     ]
    }
   ],
   "source": [
    "data=T.tensor4()\n",
    "feature_sym = FCN(data,cfg.ndim,model_name='',input_shape=(cfg.SEQ_LENGTH,3,cfg.TILE_SIZE,cfg.TILE_SIZE))[1]\n",
    "feature_fn = theano.function([data],feature_sym,allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = np.zeros((cfg.SEQ_LENGTH,3,cfg.TILE_SIZE,cfg.TILE_SIZE),dtype=np.float32)\n",
    "d[0,2,:,:] = 1\n",
    "d = feature_fn(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 16, 16, 4)\n"
     ]
    }
   ],
   "source": [
    "print d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dataset_tools import *\n",
    "from gmm_bg_substructor import BgSubstructor\n",
    "import cv2\n",
    "import numpy as np\n",
    "# params = { 'algorithm': 'grimson_gmm', \n",
    "#             'low': 1.,#*24*24,\n",
    "#             'high': 3,#.*24*24,\n",
    "#             'alpha': 0.01,\n",
    "#             'max_modes': 5,\n",
    "#             'channels': 12,\n",
    "#             'variance': .01,\n",
    "#             'bg_threshold': 0.075,\n",
    "#             'min_variance': .005,\n",
    "#             'variance_factor': 1.}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_bgs_test(feature_fn,params,out_name=cfg.NAME,dataset='test_dataset',max_l = 1000,im_size=None,verbose=False,skip_frames=200):\n",
    "    def make_bgs_features(feature_fn,x):\n",
    "        return feature_fn(np.transpose(x,(0,3,1,2)))[0]\n",
    "    out_dir = 'results/'+out_name+'_'+params['algorithm']\n",
    "    if(not os.path.exists(out_dir)):\n",
    "        os.mkdir(out_dir)\n",
    "    f = open('params.txt','w')\n",
    "    f.write('params\\n'+str(params)+'\\n')\n",
    "    f.write('max_l = %i,skip_frames=%i')\n",
    "    f.close()\n",
    "    jj = 0\n",
    "    try:\n",
    "        for d_in,d_out in iterate_folders(dataset,out_dir):\n",
    "            jj+=1\n",
    "            if(jj<1):\n",
    "                continue\n",
    "            try:\n",
    "                bgs = BgSubstructor(params)\n",
    "                i = 0\n",
    "                prev =None\n",
    "                for im,mask in iterate_video(d_in,skip_first_unlabled=True):\n",
    "                    print '%s %d                   \\r'%(d_in,i),\n",
    "                    if not (im_size is None):\n",
    "                        im,mask = resize(im,mask,im_size)\n",
    "                    if(prev is None):\n",
    "                        prev = im\n",
    "                        continue\n",
    "                    #tmp = np.concatenate((im[np.newaxis],prev[np.newaxis]),0)\n",
    "                    features = make_bgs_features(feature_fn,im.astype(np.float32))\n",
    "                    prev = im\n",
    "                    pred = bgs.update(features.astype(np.float32),im.astype(np.float32))\n",
    "                    cv2.imwrite(d_out+'/%d.png'%(i),pred)\n",
    "                    cv2.imwrite(d_out+'/%d_true.png'%(i),mask)\n",
    "                    cv2.imwrite(d_out+'/%d_input.png'%(i),im)\n",
    "                    if(verbose):\n",
    "                        cv2.imshow('pred',pred)\n",
    "                        cv2.imshow('true',mask)\n",
    "                        cv2.imshow('input',im)\n",
    "                        cv2.waitKey(1)\n",
    "                    if(i >= max_l):\n",
    "                        break\n",
    "                    i+=1\n",
    "                print '%s %d\\r'%(d_in,i),\n",
    "            finally:\n",
    "                del bgs\n",
    "    finally:\n",
    "        if(verbose):\n",
    "            cv2.destroyAllWindows()\n",
    "    print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delete bgsmentation/test_dataset/badWeather/blizzard 1000                   \n",
      "delete bgsmentation/test_dataset/baseline/highway 162                   \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-e8b7d6162a55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m                \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'../gmm_segmentation/test_dataset'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                \u001b[0mim_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m320\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m240\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                verbose=True)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-db547caf8b79>\u001b[0m in \u001b[0;36mmake_bgs_test\u001b[0;34m(feature_fn, params, out_name, dataset, max_l, im_size, verbose, skip_frames)\u001b[0m\n\u001b[1;32m     29\u001b[0m                     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_bgs_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                     \u001b[0mprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_out\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/%d.png'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_out\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/%d_true.png'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/data/Programming/motion_segmentation/gmm_segmentation2/gmm_bg_substructor/__init__.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, features, img)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbg_sub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbg_sub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_threshold_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh_threshold_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlow_threshold_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params = { \n",
    "    'algorithm': 'FTSG', \n",
    "    'th': 30, \n",
    "    'nDs': 5,\n",
    "    'nDt': 5,\n",
    "    'nAs': 5,\n",
    "    'nAt': 5,\n",
    "    'bgAlpha': 0.004,\n",
    "    'fgAlpha': 0.05,\n",
    "    'tb': 15,\n",
    "    'tf': 0.00001,\n",
    "    'tl': 0.01,\n",
    "    'init_variance' : 0.01\n",
    "} \n",
    "make_bgs_test(feature_fn,\n",
    "               out_name=cfg.NAME,\n",
    "               params=params,\n",
    "               dataset='../gmm_segmentation/test_dataset',\n",
    "               im_size=(320,240),\n",
    "               verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delete bgsmentation/dataset/badWeather/skating 1000                   \n",
      "delete bgsmentation/dataset/badWeather/snowFall 1000                   \n",
      "delete bgsmentation/dataset/badWeather/wetSnow 0                   \n",
      "delete bgsmentation/dataset/baseline/office 1000                   \n",
      "delete bgsmentation/dataset/baseline/pedestrians 799                   \n",
      "delete bgsmentation/dataset/baseline/PETS2006 223                   \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-edeb83f4b08e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m                \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'../gmm_segmentation/dataset'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                \u001b[0mim_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m320\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m240\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                verbose=True)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-db547caf8b79>\u001b[0m in \u001b[0;36mmake_bgs_test\u001b[0;34m(feature_fn, params, out_name, dataset, max_l, im_size, verbose, skip_frames)\u001b[0m\n\u001b[1;32m     29\u001b[0m                     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_bgs_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                     \u001b[0mprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_out\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/%d.png'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_out\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/%d_true.png'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/data/Programming/motion_segmentation/gmm_segmentation2/gmm_bg_substructor/__init__.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, features, img)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbg_sub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbg_sub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_threshold_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh_threshold_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlow_threshold_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params = { \n",
    "    'algorithm': 'FTSG', \n",
    "    'th': 30, \n",
    "    'nDs': 5,\n",
    "    'nDt': 5,\n",
    "    'nAs': 5,\n",
    "    'nAt': 5,\n",
    "    'bgAlpha': 0.004,\n",
    "    'fgAlpha': 0.5,\n",
    "    'tb': 4,\n",
    "    'tf': 20,\n",
    "    'tl': 0.1,\n",
    "    'init_variance': 15\n",
    "}\n",
    "make_bgs_test(lambda x : np.transpose(x,(0,2,3,1)),\n",
    "               params,\n",
    "               out_name='baseline',\n",
    "               dataset='../gmm_segmentation/test_dataset',\n",
    "               im_size=(320,240),\n",
    "               verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data,m,c,w=T.matrix(),T.matrix(),T.matrix(),T.vector()\n",
    "predict_fn = theano.function([data,m,c,w],soft_predict_sym(data,m,c,w),allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find parameters for grimpson gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../gmm_segmentation/test_dataset/badWeather/blizzard generate_features,"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-16f51de9d29f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mfind_gmm_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_frames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mim_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-16f51de9d29f>\u001b[0m in \u001b[0;36mfind_gmm_params\u001b[0;34m(feature_fn, dataset, max_frames, im_size)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterate_bathced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_frames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mim_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0min_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'generate_features,'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mgmms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_gmms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgm_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m'fit gmms'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/data/Programming/motion_segmentation/gmm_segmentation2/test_tools.pyc\u001b[0m in \u001b[0;36mmake_features\u001b[0;34m(feature_fn, imgs)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "from test_tools import make_features,make_gmms,fit_gmms,predict_pixelwise\n",
    "from dataset_tools import *\n",
    "\n",
    "\n",
    "def find_gmm_params(feature_fn,\n",
    "              dataset='../gmm_segmentation/test_dataset',\n",
    "              max_frames=300,\n",
    "              im_size = (320//2,240//2)):\n",
    "    all_covars = []\n",
    "    all_weights = []\n",
    "    all_comp = []\n",
    "    all_masks = []\n",
    "    for k,in_dir in enumerate(iterate_folders(dataset)):\n",
    "        for i,(imgs,masks) in enumerate(iterate_bathced(in_dir,max_frames,im_size)):\n",
    "            print in_dir,'generate_features,',\n",
    "            data = make_features(feature_fn,imgs)\n",
    "            gmms = make_gmms(imgs.shape[1:-1],cfg.gm_num)\n",
    "            print 'fit gmms'\n",
    "            fit_gmms(data,gmms,None)\n",
    "            cov = np.empty((len(gmms),)+gmms[0].covariances_.shape,dtype=np.float32)\n",
    "            weights = np.empty((len(gmms),len(gmms[0].weights_)),dtype=np.float32)\n",
    "            dists = np.empty((len(gmms),len(imgs),len(gmms[0].weights_)),dtype=np.float32)\n",
    "            data = data.reshape((len(imgs),-1,gmms[i].means_.shape[1]))\n",
    "            for j in range(len(gmms)):\n",
    "                cov[j] = gmms[j].covariances_\n",
    "                weights[j] = gmms[j].weights_\n",
    "                dists[j] = ((data[:,j,None,:]-gmms[j].means_[None,:,:])**2).sum(-1)\n",
    "            print 'cov',cov.mean(),cov.std()\n",
    "            masks = masks.reshape((len(masks),-1))\n",
    "            masks = np.transpose(masks,(1,0))\n",
    "            print 'cov bg',dists[masks < 0.5].min(-1).mean(),dists[masks < 0.1].min(-1).std()\n",
    "            print 'cov motion',dists[masks > 0.5].min(-1).mean(),dists[masks > 0.9].min(-1).std()\n",
    "            print 'std motion',data[masks > 0.9].std()\n",
    "            break\n",
    "    print 'test complete'\n",
    "    \n",
    "    \n",
    "find_gmm_params(feature_fn,max_frames=70,im_size=(50,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from test_tools import make_features,make_gmms,fit_gmms,predict_pixelwise\n",
    "from dataset_tools import *\n",
    "def make_test_as_train(feature_fn,predict_fn,\n",
    "              out_dir='results/'+cfg.NAME,\n",
    "              dataset='dataset',\n",
    "              max_frames=300,\n",
    "              im_size = (320//2,240//2)):\n",
    "    for in_dir,out_dir in iterate_folders(dataset,out_dir):\n",
    "        for i,(imgs,masks) in enumerate(iterate_bathced(in_dir,max_frames,im_size)):\n",
    "            if(masks[(masks>30) & (masks < 240)].size > 0.1*masks.size):\n",
    "                continue\n",
    "            print in_dir,'generate_features,',\n",
    "            data = make_features(feature_fn,imgs)\n",
    "            gmms = make_gmms(imgs.shape[1:-1],cfg.gm_num)\n",
    "            print 'fit gmms,',\n",
    "            fit_gmms(data[:100],gmms,masks[:100])\n",
    "            print 'predict,',\n",
    "            prediction = predict_pixelwise(data[100:],gmms,predict_fn)\n",
    "            print 'save'\n",
    "            imgs = imgs[100:]\n",
    "            masks = masks[100:]      \n",
    "            prediction = (prediction*255).astype(np.uint8)\n",
    "            for i in range(len(imgs)):\n",
    "                cv2.imwrite(out_dir+'/'+str(i)+'.png',prediction[i])\n",
    "                cv2.imwrite(out_dir+'/'+str(i)+'_true.png',masks[i])\n",
    "                cv2.imwrite(out_dir+'/'+str(i)+'_input.jpg',imgs[i])\n",
    "            break\n",
    "            print ''\n",
    "    print 'test complete'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../gmm_segmentation/test_dataset/badWeather/blizzard generate_features,"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-6b299fcc38b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m make_test_as_train(feature_fn,predict_fn,\n\u001b[1;32m      2\u001b[0m                    \u001b[0mout_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'results/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNAME\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_tat'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                    dataset='../gmm_segmentation/test_dataset')\n\u001b[0m",
      "\u001b[0;32m<ipython-input-43-d1c728c08287>\u001b[0m in \u001b[0;36mmake_test_as_train\u001b[0;34m(feature_fn, predict_fn, out_dir, dataset, max_frames, im_size)\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0min_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'generate_features,'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mgmms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_gmms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgm_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m'fit gmms,'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/data/Programming/motion_segmentation/gmm_segmentation2/test_tools.pyc\u001b[0m in \u001b[0;36mmake_features\u001b[0;34m(feature_fn, imgs)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "make_test_as_train(feature_fn,predict_fn,\n",
    "                   out_dir='results/'+cfg.NAME+'_tat',\n",
    "                   dataset='../gmm_segmentation/test_dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calc metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/conv3_net_with_color_ndim9_FTSG/badWeather/blizzard\n",
      "AveragePrecision: 0.0\n",
      "FNR: 0.444309717241\n",
      "Recall: 0.555690282759\n",
      "Sp: 0.99906276319\n",
      "Precision: 0.909148756021\n",
      "PWC: 0.829626546017\n",
      "FPR: 0.000937236810338\n",
      "F_Measure: 0.68977562166\n",
      "\n",
      "results/conv3_net_with_color_ndim9_FTSG/baseline/highway\n",
      "AveragePrecision: 0.0\n",
      "FNR: 0.0708977856914\n",
      "Recall: 0.929102214309\n",
      "Sp: 0.9763472231\n",
      "Precision: 0.697455851039\n",
      "PWC: 2.62717720708\n",
      "FPR: 0.0236527769002\n",
      "F_Measure: 0.796784067397\n",
      "\n",
      "total result\n",
      "AveragePrecision: 0.0\n",
      "FNR: 0.257603751466\n",
      "Recall: 0.742396248534\n",
      "Sp: 0.987704993145\n",
      "Precision: 0.80330230353\n",
      "PWC: 1.72840187655\n",
      "FPR: 0.0122950068552\n",
      "F_Measure: 0.743279844529\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "import os\n",
    "\n",
    "def calc_metrics_imgs(predict,label):\n",
    "    predict,label = predict.flatten(),label.flatten()\n",
    "    mask = (label>230)|(label < 50)\n",
    "    p = (predict.astype(np.float32)/255.)[mask]\n",
    "    y = (label.astype(np.float32)/255.)[mask]\n",
    "    y[y>0.5] = 1.\n",
    "    y[y<=0.5] = 0.\n",
    "    bp = np.zeros_like(p)\n",
    "    bp[p>0.5] = 1.\n",
    "    TP = (bp*y).sum()\n",
    "    TN = ((1-bp)*(1-y)).sum()\n",
    "    FP = (bp*(1.0-y)).sum()\n",
    "    FN = ((1.0-bp)*y).sum()\n",
    "    AveragePrecision = 0#average_precision_score(y,p)\n",
    "    return np.array([TP,TN,FP,FN],dtype=np.int64),AveragePrecision\n",
    "    \n",
    "\n",
    "def print_results(results):\n",
    "    s = ''\n",
    "    for k in results.keys():\n",
    "        s=s+k+str(': ')+str(results[k])+'\\n'\n",
    "    return s\n",
    "\n",
    "def calc_metrics_folder(data_dir):\n",
    "    S = np.array([0,0,0,0],dtype=np.int64)\n",
    "    AveragePrecision = 0.0\n",
    "    nums = [int(i[:-4]) for i in os.listdir(data_dir) if i.find('true') < 0 and  i.find('input') < 0]\n",
    "    for i in nums:\n",
    "        m = cv2.imread(data_dir+'/%i_true.png'%(i))\n",
    "        p = cv2.imread(data_dir+'/%i.png'%(i))\n",
    "        cv2.imshow('p',p)\n",
    "        cv2.waitKey(1)\n",
    "        _s = calc_metrics_imgs(p,m)\n",
    "        AveragePrecision += _s[1]\n",
    "        S+=_s[0]\n",
    "        \n",
    "    TP,TN,FP,FN = S[0],S[1],S[2],S[3]\n",
    "    if(S.min() <= 0):\n",
    "        results = dict( AveragePrecision = 0,\\\n",
    "                        Recall = np.nan,\\\n",
    "                        Sp = np.nan,\\\n",
    "                        FPR = np.nan,\\\n",
    "                        FNR = np.nan,\\\n",
    "                        PWC =  np.nan,\\\n",
    "                        F_Measure  =  np.nan,\\\n",
    "                        Precision  = np.nan)\n",
    "    else:\n",
    "        results = dict( AveragePrecision = AveragePrecision/float(len(nums)),\\\n",
    "                        Recall = TP / float(TP + FN),\\\n",
    "                        Sp = TN / float(TN + FP),\\\n",
    "                        FPR = FP / float(FP + TN),\\\n",
    "                        FNR = FN / float(TP + FN),\\\n",
    "                        PWC =  100 * (FN + FP) / float(TP + FN + FP + TN),\\\n",
    "                        F_Measure  =  (2 * (TP / float(TP + FP)) * (TP / float(TP + FN))) / (TP / float(TP + FP) +  TP / float(TP + FN)),\\\n",
    "                        Precision  = TP / float(TP + FP))\n",
    "\n",
    "    print data_dir\n",
    "    print print_results(results)\n",
    "    return results\n",
    "\n",
    "def calc_metric_all_folders(data_dir):\n",
    "    res = []\n",
    "    f = open(data_dir+'.txt','w')\n",
    "    list_dirs = []\n",
    "    for j in os.listdir(data_dir):\n",
    "        list_dirs = list_dirs+[data_dir+'/'+j+'/'+i for i in os.listdir(data_dir+'/'+j)]\n",
    "    \n",
    "    for folder in list_dirs:\n",
    "        results = calc_metrics_folder(folder)\n",
    "        if not (results is None):\n",
    "            res.append(results)\n",
    "            f.write(folder+'\\n')\n",
    "            f.write(print_results(results))\n",
    "    results = dict()\n",
    "    for k in res[0].keys():\n",
    "        results[k] = np.array([i[k] for i in res if np.isfinite(i[k])]).mean()\n",
    "    f.write('total result\\n')\n",
    "    f.write(print_results(results))\n",
    "    f.close()\n",
    "    print 'total result'\n",
    "    print print_results(results)\n",
    "\n",
    "calc_metric_all_folders('results/'+cfg.NAME+'_FTSG')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
