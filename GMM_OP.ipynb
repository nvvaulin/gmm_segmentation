{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 5110 on context None\n",
      "Mapped name None to device cuda0: GeForce GTX 660 Ti (0000:01:00.0)\n"
     ]
    }
   ],
   "source": [
    "import theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from theano import gradient,function\n",
    "import numpy as np\n",
    "import theano.tensor as T\n",
    "from sklearn import mixture\n",
    "from theano_utils import calc_log_prob_gauss_vector\n",
    "\n",
    "class GMM():\n",
    "    def __init__(self,gm_num):\n",
    "        self.X = None\n",
    "        self.gmm = mixture.GaussianMixture(covariance_type='diag',n_components=gm_num, max_iter=2000)\n",
    "        \n",
    "    def fit(self,X):\n",
    "        if(not self.X is None):\n",
    "            if(self.X.shape == X.shape):\n",
    "                if(np.abs(self.X-X).mean()<1e-10):\n",
    "                    return ;\n",
    "        self.X = X\n",
    "        self.gmm.fit(X)\n",
    "        \n",
    "    @property\n",
    "    def weights_(self):\n",
    "        return self.gmm.weights_\n",
    "    \n",
    "    @property\n",
    "    def covariances_(self):\n",
    "        return self.gmm.covariances_\n",
    "    \n",
    "    @property\n",
    "    def means_(self):\n",
    "        return self.gmm.means_\n",
    "        \n",
    "        \n",
    "class GMMOp(theano.Op):\n",
    "    def __init__(self,gm_num,ndim,gmm=None):\n",
    "        \"\"\"\n",
    "        fit gmm with diagonal covariances to input vectors\n",
    "        input: vector[n_samples*n_dim] flattened\n",
    "        output: vector means[gm_num*n_dim],covars[gm_num*n_dim],weights[gm_num], flattened\n",
    "        \"\"\"\n",
    "        super(GMMOp, self).__init__()\n",
    "        self.otypes = [T.fvector]\n",
    "        self.itypes = [T.fvector]\n",
    "        self.gm_num = gm_num\n",
    "        self.ndim = ndim\n",
    "        if(gmm is None):\n",
    "            self.gmm =GMM(self.gm_num)\n",
    "        else:\n",
    "            self.gmm = gmm\n",
    "        self.reg_coef = 1e-5\n",
    "\n",
    "    def perform(self, node, (X,), output_storage):       \n",
    "        self.gmm.fit(X.reshape((-1,self.ndim)))\n",
    "        means = self.gmm.means_.flatten()\n",
    "        covars = self.gmm.covariances_.flatten()\n",
    "        weights = self.gmm.weights_.flatten()\n",
    "        output_storage[0][0] = np.concatenate((means,covars,weights)).astype(np.float32)\n",
    "            \n",
    "    def build_lagrangian(self,Yvec,meansvec,covarsvec,weights,lam):\n",
    "        n_dim = self.ndim\n",
    "        gm_num = self.gm_num\n",
    "        Y = Yvec.reshape((-1,n_dim))\n",
    "        means = T.reshape(meansvec, (gm_num, n_dim))\n",
    "        covars = T.reshape(covarsvec, (gm_num,n_dim))\n",
    "        log_prob = calc_log_prob_gauss_vector(Y, means,covars,weights)        \n",
    "        return T.sum(log_prob) + lam * (T.sum(weights) - 1) \n",
    "        \n",
    "    def build_linear_system(self,Yvec,meansvec,covarsvec,weights,lam):\n",
    "        n_dim = self.ndim\n",
    "        gm_num = self.gm_num\n",
    "        lagrangian = self.build_lagrangian(Yvec,meansvec,covarsvec,weights,lam)\n",
    "        d_lagrangian = gradient.jacobian(lagrangian, [meansvec, covarsvec, weights],\\\n",
    "                              consider_constant=[Yvec, meansvec, covarsvec, weights])\n",
    "        hm = gradient.jacobian(d_lagrangian[0], [Yvec, meansvec, covarsvec, weights],\\\n",
    "                              consider_constant=[Yvec, meansvec, covarsvec, weights])\n",
    "        hc = gradient.jacobian(d_lagrangian[1], [Yvec, meansvec, covarsvec, weights],\\\n",
    "                              consider_constant=[Yvec, meansvec, covarsvec, weights])\n",
    "        hw = gradient.jacobian(d_lagrangian[2], [Yvec, meansvec, covarsvec, weights, lam],\\\n",
    "                              consider_constant=[Yvec, meansvec, covarsvec, weights,lam])\n",
    "        \n",
    "        mean_row = T.concatenate((hm[1], hm[2], hm[3], T.zeros((n_dim*gm_num, 1))), axis=1)\n",
    "        cov_row = T.concatenate((hc[1], hc[2], hc[3], T.zeros((n_dim*gm_num, 1))), axis=1)\n",
    "        \n",
    "        weight_row = T.concatenate((hw[1], hw[2], hw[3], T.reshape(hw[4], (gm_num, 1))), axis=1)\n",
    "        lambda_row = T.concatenate(\n",
    "            (T.zeros((1, 2*n_dim*gm_num)),\n",
    "             T.reshape(hw[4], (1, gm_num)),\n",
    "             T.zeros((1, 1))), axis=1)\n",
    "        M = T.concatenate((mean_row, cov_row, weight_row, lambda_row))\n",
    "        N = T.concatenate((-hm[0], -hc[0], -hw[0], T.zeros((1, hw[0].shape[1]))))\n",
    "        return N,M#MX = N\n",
    "    \n",
    "    def solve_diag_linear(self,N,a,b,c,D):#MX=N\n",
    "        '''\n",
    "          |A B _|\n",
    "        M=|_ C _|\n",
    "          |_ _ D|\n",
    "        '''\n",
    "        n_dim = self.ndim\n",
    "        gm_num = self.gm_num\n",
    "        n_samples = N.shape[1]//n_dim\n",
    "        a = a + T.ones_like(a)*self.reg_coef\n",
    "        c = c + T.ones_like(c) * self.reg_coef\n",
    "        D = D + T.eye(D.shape[0]) * self.reg_coef\n",
    "        e = 1. / (a - b / c * b)\n",
    "        f = -e * b / c\n",
    "        h = (T.ones_like(a) - f * b) / c\n",
    "        \n",
    "        e = e.reshape((gm_num,n_dim))\n",
    "        h = h.reshape((gm_num,n_dim))\n",
    "        f = f.reshape((gm_num,n_dim))\n",
    "        \n",
    "        eye = T.eye(n_dim)            \n",
    "        mu = N[:gm_num*n_dim].reshape((gm_num,n_dim,n_samples,n_dim))*eye[None,:,None,:]\n",
    "        cov = N[gm_num*n_dim:2*gm_num*n_dim].reshape((gm_num,n_dim,n_samples,n_dim))*eye[None,:,None,:]\n",
    "        dX1 = e[:,None,None,:] * mu + f[:,None,None,:] * cov\n",
    "        dX2 = f[:,None,None,:] * mu + h[:,None,None,:] * cov\n",
    "        \n",
    "        \n",
    "        dX1 = dX1.reshape((-1,n_samples*n_dim))\n",
    "        dX2 = dX2.reshape((-1,n_samples*n_dim))        \n",
    "        Di = T.nlinalg.matrix_inverse(D)\n",
    "        dX3 = Di.dot(N[n_dim * 2 * gm_num:, :])\n",
    "        \n",
    "        dX = T.concatenate((dX1,dX2,dX3),axis=0)\n",
    "        return dX\n",
    "        \n",
    "    def solve_general_linear(self,N,M):#MX=N\n",
    "        M = M + self.reg_coef * T.eye(M.shape[0])\n",
    "        Mi = T.nlinalg.matrix_inverse(M)\n",
    "        return M.dot(N)\n",
    "    \n",
    "    def solve_linear_system(self,N,M):\n",
    "        par_dim = self.ndim*self.gm_num\n",
    "        def diag(M):            \n",
    "            a = T.diag(M)\n",
    "            A = T.diag(a)\n",
    "            return a,abs(A - M).sum()\n",
    "        a,na = diag(M[0:par_dim, 0:par_dim])\n",
    "        b,nb = diag(M[0:par_dim, par_dim:2 * par_dim])\n",
    "        c,nc = diag(M[par_dim:2 * par_dim, par_dim:2 * par_dim])\n",
    "        D = M[2 * par_dim:, 2 * par_dim:]\n",
    "        return theano.ifelse.ifelse(T.le(na+nb+nc,1e-6),\\\n",
    "                             self.solve_diag_linear(N,a,b,c,D),\\\n",
    "                             self.solve_general_linear(N,M))\n",
    "        return dX\n",
    "    \n",
    "    def grad(self, (Yvec,), output_grads):\n",
    "        gm_num,ndim = self.gm_num,self.ndim\n",
    "        gmm_res = GMMOp(gm_num,ndim,self.gmm)(Yvec)\n",
    "        meansvec = gmm_res[:gm_num*ndim]\n",
    "        covarsvec = gmm_res[gm_num*ndim:2*gm_num*ndim]\n",
    "        weights = gmm_res[gm_num*ndim*2:]\n",
    "        n_samples = Yvec.shape[0]//self.ndim\n",
    "        N,M = self.build_linear_system(Yvec,meansvec, covarsvec, weights, n_samples)\n",
    "        dX = self.solve_linear_system(N,M)\n",
    "        return [output_grads[0].dot(dX[0:dX.shape[0]-1, :])]\n",
    "\n",
    "\n",
    "def get_gmm(X,gm_num,ndims):\n",
    "    f = GMMOp(gm_num,ndims)(X.flatten())\n",
    "    means = f[:gm_num*ndims].reshape((gm_num,ndims))\n",
    "    covars = f[gm_num*ndims:2*gm_num*ndims].reshape((gm_num,ndims))\n",
    "    weights = f[2*gm_num*ndims:]\n",
    "    return means,covars,weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dif mean,dif cov, w 1.25845e-08 0.0146019 1.0\n",
      "dif mean,dif cov, w 1.37446e-10 0.0001 0.0\n"
     ]
    }
   ],
   "source": [
    "def test_1_gmm(n_samp,dim):\n",
    "    X = T.fmatrix(\"X\")\n",
    "    m1,c1,w1 =  get_gmm(X,1,dim)\n",
    "    \n",
    "    m2 = T.mean(X,axis=0).reshape((1,-1))\n",
    "    c2 = (T.std(X,axis=0)+0.0001).reshape((1,-1))\n",
    "    \n",
    "    f = function([X],[m1,c1,w1,m2,c2])\n",
    "    res = f(np.random.randn(n_samp,dim).astype(np.float32))\n",
    "    \n",
    "    print'dif mean,dif cov, w', np.abs(res[0]-res[3]).mean(),np.abs(res[1]-res[4]).mean(),np.abs(res[2]).sum()\n",
    "    \n",
    "    dm1 = gradient.jacobian(m1.flatten(),[X])\n",
    "    dc1 = gradient.jacobian(c1.flatten(),[X])\n",
    "    dw1 = gradient.jacobian(w1.flatten(),[X])\n",
    "    dm2 = gradient.jacobian(m2.flatten(),[X])\n",
    "    dc2 = gradient.jacobian(m2.flatten(),[X])\n",
    "    \n",
    "    df = function([X],dm1+dc1+dw1+dm2+dc2)\n",
    "    res = df((np.random.randn(n_samp,dim)*0.1+3.).astype(np.float32))\n",
    "    print'dif mean,dif cov, w', np.abs(res[0]-res[3]).mean(),np.abs(res[1]-res[4]).mean(),np.abs(res[2]).sum()\n",
    "\n",
    "    \n",
    "test_1_gmm(1000,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = T.fmatrix(\"X\")\n",
    "m1,c1,w1 =  get_gmm(X,2,10)\n",
    "\n",
    "m2 = T.mean(X,axis=0).reshape((1,-1))\n",
    "c2 = (T.std(X,axis=0)+0.0001).reshape((1,-1))\n",
    "dm1 = gradient.jacobian(m1.flatten(),[X])\n",
    "dc1 = gradient.jacobian(c1.flatten(),[X])\n",
    "dw1 = gradient.jacobian(w1.flatten(),[X])\n",
    "\n",
    "df = function([X],dm1+dc1+dw1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 211 ms per loop\n"
     ]
    }
   ],
   "source": [
    "data = (np.random.randn(1000,10)*0.1+3.).astype(np.float32)\n",
    "%timeit df(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gradient.numeric_grad()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
