{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 5105 on context None\n",
      "Mapped name None to device cuda: GeForce GT 740M (0000:01:00.0)\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "from theano import gradient,function\n",
    "import numpy as np\n",
    "import theano.tensor as T\n",
    "from sklearn import mixture\n",
    "from gmm_op import GMMOp,calc_log_prob_gmm,get_gmm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_mixture(ns,dim,sigm=.3):\n",
    "    ns = np.array(ns)\n",
    "    means = []\n",
    "    covs = []\n",
    "    weights = ns.astype(np.float32)/ns.sum()\n",
    "    res = np.zeros((int(sum(ns)),dim),dtype=np.float32)\n",
    "    i = 0\n",
    "    for n in ns:\n",
    "        covs.append(sigm*(np.random.rand(dim)+1.))\n",
    "        means.append(10*(np.random.rand(dim)))\n",
    "        res[i:i+n] = np.random.randn(n,dim)*covs[-1][None,:]+means[-1][None,:]\n",
    "        covs[-1] = np.std(res[i:i+n],0)**2\n",
    "        means[-1] = np.mean(res[i:i+n],0)\n",
    "        i=i+n\n",
    "    return res,np.array(means),np.array(covs),weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test calc_log_prob_gauss_vector\n",
      "|loglikelihood_pred-loglikelihood_true|/|loglikelihood_true|:\n",
      "mean: 1.49185173912e-06\n",
      "max: 1.94841947864e-06\n"
     ]
    }
   ],
   "source": [
    "def test_calc_log_prob_gmm(gm_num=2,ndim=10):\n",
    "    print 'test calc_log_prob_gauss_vector'\n",
    "    gmm = mixture.GaussianMixture(covariance_type='diag',\n",
    "                                   n_components=gm_num,\n",
    "                                   max_iter=2000,\n",
    "                                   warm_start=False)\n",
    "    Y,m,c,w = T.fmatrix(),T.fmatrix(),T.fmatrix(),T.fvector()\n",
    "    f = function([Y,m,c,w],calc_log_prob_gmm(Y,m,c,w),allow_input_downcast=True)\n",
    "    print '|loglikelihood_pred-loglikelihood_true|/|loglikelihood_true|:'\n",
    "    res = []\n",
    "    for i in range(10):\n",
    "        data,_,_,_=gen_mixture(np.random.randint(100,1000,gm_num),ndim)\n",
    "        gmm.fit(data)\n",
    "        p = f(data,gmm.means_,gmm.covariances_,gmm.weights_)\n",
    "        p1 = gmm.score_samples(data)\n",
    "        res.append(np.linalg.norm(p1-p)/np.linalg.norm(p1))\n",
    "    res = np.array(res)\n",
    "    print 'mean:',res.mean()\n",
    "    print 'max:',res.max()\n",
    "            \n",
    "test_calc_log_prob_gmm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test d(calc_log_prob_gauss_vector)/d(m,c,w) = 0 for 1 component\n",
      "|dm|/|m|,|dc|/|c|:\n",
      "mean: [ 0.00053602  0.02163022]\n",
      "max: [ 0.00157368  0.0420338 ]\n"
     ]
    }
   ],
   "source": [
    "def test_max_likelihood(verbose=True,ndim=10,sigm=0.1):  \n",
    "    print 'test d(calc_log_prob_gauss_vector)/d(m,c,w) = 0 for 1 component'\n",
    "    Y,m,c = T.fmatrix(),T.fmatrix(),T.fmatrix()\n",
    "    lag = T.sum(calc_log_prob_gauss_vector(Y,m,c))\n",
    "    jac = T.grad(lag,[m,c])\n",
    "    f = function([Y,m,c],jac+[lag],allow_input_downcast=True)\n",
    "    print '|dm|/|m|,|dc|/|c|:'\n",
    "    res = []\n",
    "    for i in range(10):\n",
    "        data,m,c,w = gen_mixture([100],ndim,sigm=sigm)\n",
    "        d = f(data,m,c)\n",
    "        n = [np.linalg.norm(d[0])/np.linalg.norm(m),\\\n",
    "            np.linalg.norm(d[1])/np.linalg.norm(c)]\n",
    "        res.append(n)\n",
    "    res = np.array(res)\n",
    "    print 'mean:',res.mean(0)\n",
    "    print 'max:',res.max(0)\n",
    "    \n",
    "test_max_likelihood(ndim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test d_lagrangian / d(mcwl) = 0\n",
      "|dm|/|m|,|dc|/|c|,|dw|/|w|:\n",
      "[[  1.8076e-02   2.7011e-01   5.2894e+03   0.0000e+00]\n",
      " [  1.3794e-02   2.8369e-01   3.2106e+03   0.0000e+00]\n",
      " [  1.1687e-02   3.5540e-01   5.4209e+03   0.0000e+00]\n",
      " [  7.5737e-03   7.1341e-02   3.2941e+03   0.0000e+00]\n",
      " [  6.3758e-03   1.1993e-01   3.0442e+03   0.0000e+00]\n",
      " [  1.3199e-02   2.1930e-01   5.1110e+03   0.0000e+00]\n",
      " [  5.7152e-03   6.8865e-02   1.9481e+03   0.0000e+00]\n",
      " [  1.1502e-02   2.2135e-01   4.0975e+03   0.0000e+00]\n",
      " [  1.1639e-03   2.6775e-02   1.1708e+03   0.0000e+00]\n",
      " [  4.9045e-03   8.7987e-02   2.4895e+03   0.0000e+00]]\n",
      "mean: [  9.3991e-03   1.7248e-01   3.5076e+03   0.0000e+00]\n",
      "max: [  1.8076e-02   3.5540e-01   5.4209e+03   0.0000e+00]\n"
     ]
    }
   ],
   "source": [
    "def test_lagrangian(gm_num=2,ndim=10,sigm=0.3):    \n",
    "    print 'test d_lagrangian / d(mcwl) = 0'\n",
    "    Y,m,c,w,l = T.fmatrix(),T.fmatrix(),T.fmatrix(),T.fvector(),T.fscalar()\n",
    "    lag = GMMOp.build_lagrangian(Y,m,c,w,l)\n",
    "    jac = T.grad(lag,[m,c,w,l])\n",
    "    f = function([Y,m,c,w,l],jac+[lag],allow_input_downcast=True)\n",
    "    print '|dm|/|m|,|dc|/|c|,|dw|/|w|:'\n",
    "    res = []\n",
    "    for i in range(10):\n",
    "        data,m,c,w = gen_mixture(np.random.randint(100,1000,gm_num),ndim,sigm=sigm)\n",
    "        l = np.float32(len(data))\n",
    "        d = f(data,m,c,w,l)\n",
    "        n = [np.linalg.norm(d[0])/np.linalg.norm(m),\\\n",
    "            np.linalg.norm(d[1])/np.linalg.norm(c),\\\n",
    "            np.linalg.norm(d[2])/np.linalg.norm(w),\\\n",
    "            float(d[-2])]\n",
    "        res.append(n)\n",
    "    res = np.array(res)\n",
    "    print 'mean:',res.mean(0)\n",
    "    print 'max:',res.max(0)\n",
    "test_lagrangian(gm_num=2,ndim=10,sigm=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test build_linear_system (solution=true_solution) for 1 component\n",
      "|dm|/|m|,|dc|/|c|:\n",
      "mean: [  1.53074482e-05   1.03449397e-07]\n",
      "max: [  4.45331832e-05   2.21478088e-07]\n"
     ]
    }
   ],
   "source": [
    "def test_build_lin_system(ndim=10,sigm=0.1):    \n",
    "    print 'test build_linear_system (solution=true_solution) for 1 component'\n",
    "    Y = T.fvector()\n",
    "    m = T.mean(Y.reshape((-1,ndim)),axis=0).flatten()\n",
    "    c = T.std(Y.reshape((-1,ndim)),axis=0).flatten()**2\n",
    "    w = T.ones(1)\n",
    "    l = T.reshape(Y.shape[0]//ndim,(1,))\n",
    "    mcwl = T.concatenate((m,c,w,l))    \n",
    "    N,M = GMMOp(1,ndim).build_linear_system(Y,mcwl)\n",
    "    dmcwl = function([Y],gradient.jacobian(mcwl,[Y])+[N,M])\n",
    "    print '|dm|/|m|,|dc|/|c|:'\n",
    "    rres = []\n",
    "    for i in range(10):\n",
    "        data,_,_,_=gen_mixture([1000],ndim,sigm=sigm)\n",
    "        res = dmcwl(data.flatten().astype(np.float32))\n",
    "        sol = np.linalg.solve(res[2],res[1])\n",
    "        n = [(np.linalg.norm(sol[:ndim]-res[0][:ndim])/np.linalg.norm(res[0][ndim])),\\\n",
    "            (np.linalg.norm(sol[ndim:2*ndim]-res[0][ndim:2*ndim])/np.linalg.norm(res[0][ndim:2*ndim]))]\n",
    "        rres.append(n)\n",
    "    rres = np.array(rres)\n",
    "    print 'mean:',rres.mean(0)\n",
    "    print 'max:',rres.max(0)\n",
    "test_build_lin_system(ndim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test solve_linear_system (solution=true_solution)\n",
      "|MX-N|/|N|:\n",
      "mean: 1.97428532133e-14\n",
      "max: 6.02046725027e-14\n",
      "test solve_linear_system (solution=true_solution)\n",
      "|MX-N|/|N|:\n",
      "mean: 1.1618514181e-16\n",
      "max: 2.02084835299e-16\n",
      "test solve_linear_system (solution=true_solution)\n",
      "|MX-N|/|N|:\n",
      "mean: 3.17812330367e-16\n",
      "max: 6.97815972011e-16\n"
     ]
    }
   ],
   "source": [
    "def test_solve_linear_system(gm_num = 2,ndim=10,sigm=0.01):    \n",
    "    print 'test solve_linear_system (solution=true_solution)'\n",
    "    Y = T.fmatrix()\n",
    "    m = T.fmatrix()\n",
    "    c = T.fmatrix()\n",
    "    w = T.fvector()\n",
    "    l = T.reshape(Y.shape[0]//ndim,(1,))\n",
    "    mcwl = T.concatenate((m.flatten(),c.flatten(),w,l)) \n",
    "    gmm_op = GMMOp(gm_num,ndim)\n",
    "    N,M = gmm_op.build_linear_system(Y.flatten(),mcwl)\n",
    "    sol = gmm_op.solve_linear_system(N,M)\n",
    "    f = function([Y,m,c,w],[sol,N,M],allow_input_downcast=True)\n",
    "    rres = []\n",
    "    print '|MX-N|/|N|:'\n",
    "    for i in range(10):\n",
    "        data,m,c,w=gen_mixture(np.random.randint(100,1000,gm_num),ndim,sigm=sigm)\n",
    "        res = f(data,m,c,w)\n",
    "        sol = res[0]\n",
    "        M = res[2]\n",
    "        N = res[1]\n",
    "        n = np.linalg.norm(M.dot(sol)-N)/np.linalg.norm(N)\n",
    "        rres.append(n)\n",
    "    rres = np.array(rres)\n",
    "    print 'mean:',rres.mean(0)\n",
    "    print 'max:',rres.max(0)\n",
    "test_solve_linear_system(ndim=1,sigm=1.)\n",
    "test_solve_linear_system(ndim=3,sigm=.001)\n",
    "test_solve_linear_system(ndim=3,sigm=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test gradient for 1 component\n",
      "|d_true-d_predicted|\n",
      "mean: [  4.51154705e-07   1.04997853e-05]\n",
      "max: [  5.29037720e-07   1.16022975e-05]\n"
     ]
    }
   ],
   "source": [
    "def test_gmm_1(ndim=10,sigm=0.3):   \n",
    "    print 'test gradient for 1 component'\n",
    "    X = T.fmatrix(\"X\")\n",
    "    mcw = GMMOp(1,ndim)(X.flatten())    \n",
    "    m2 = T.mean(X,axis=0).flatten()\n",
    "    c2 = (T.std(X,axis=0)**2).flatten()\n",
    "    mcw1 = T.concatenate((m2,c2,T.ones(1)))\n",
    "    d_mcw = gradient.jacobian(mcw,[X])[0]\n",
    "    d_mcw1 = gradient.jacobian(mcw1,[X])[0]\n",
    "    f = function([X],[d_mcw,d_mcw1],allow_input_downcast=True)\n",
    "    print'|d_true-d_predicted|'\n",
    "    rres = []\n",
    "    for i in range(10):\n",
    "        data,_,_,_=gen_mixture([1000],ndim,sigm=sigm)\n",
    "        res = f(data.astype(np.float32))\n",
    "        n = [np.abs(res[0][:ndim]-res[1][:ndim]).mean()/np.abs(res[1][:ndim]).mean(),\\\n",
    "            np.abs(res[0][ndim:2*ndim]-res[1][ndim:2*ndim]).mean()/np.abs(res[1][ndim:2*ndim]).mean()]\n",
    "        rres.append(n)\n",
    "    rres = np.array(rres)\n",
    "    print 'mean:',rres.mean(0)\n",
    "    print 'max:',rres.max(0)\n",
    "\n",
    "test_gmm_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision for accurate grad\n",
      "get numerical gradient and compare it with symbolic\n",
      "sigma,|sym-num|,|sym-num|/|num|\n",
      "[[  1.0000e-05   1.0453e-03   1.1546e-02]\n",
      " [  4.0000e-05   3.8007e-04   2.9452e-03]\n",
      " [  1.6000e-04   7.7114e-04   2.9547e-03]\n",
      " [  6.4000e-04   3.8398e-04   2.0677e-03]\n",
      " [  2.5600e-03   3.7115e-04   1.9296e-03]\n",
      " [  1.0240e-02   5.8450e-04   1.6323e-03]\n",
      " [  4.0960e-02   1.2951e-03   2.9518e-03]\n",
      " [  1.6384e-01   9.9572e-04   4.9606e-03]\n",
      " [  6.5536e-01   8.5524e-04   4.9148e-03]\n",
      " [  2.6214e+00   1.5866e-03   4.0232e-03]]\n",
      "mean: [ 0.3495  0.0008  0.004 ]\n",
      "max: [  2.6214e+00   1.5866e-03   1.1546e-02]\n"
     ]
    }
   ],
   "source": [
    "from gmm_op import GMM\n",
    "\n",
    "def test_numeric(gm_num=2,ndim=5,sigm=0.00001,use_approx_grad=False):    \n",
    "    print 'get numerical gradient and compare it with symbolic'\n",
    "    X = T.fvector()\n",
    "    gmm = GMM(gm_num)\n",
    "    rvec  =T.fvector()\n",
    "    gmm_op = T.sum(rvec*GMMOp(gm_num,ndim,gmm,use_approx_grad=use_approx_grad)(X))\n",
    "    f = function([rvec,X],gmm_op,allow_input_downcast=True)\n",
    "    fg = function([rvec,X],[gmm_op]+T.grad(gmm_op,[X]),allow_input_downcast=True)\n",
    "    \n",
    "    def calc_num_grad(rvec,X,eps):\n",
    "        f0,sym_grad = tuple(fg(rvec,X))\n",
    "        num_grad = np.zeros_like(sym_grad)\n",
    "        for i in range(len(X)):\n",
    "            dX = np.zeros_like(X)\n",
    "            dX[i] = eps\n",
    "            num_grad[i] = f(rvec,X+dX)\n",
    "        num_grad = (num_grad-f0)/eps\n",
    "        return sym_grad,num_grad\n",
    "    res = []\n",
    "    print 'sigma,|sym-num|,|sym-num|/|num|'\n",
    "    for i in range(10):\n",
    "        data,m,c,w = gen_mixture(np.random.randint(10,100,gm_num),ndim,sigm=sigm)\n",
    "        rvec = np.random.rand(m.size+c.size+w.size)\n",
    "        rvec = rvec/np.linalg.norm(rvec)\n",
    "        sym_grad,num_grad = calc_num_grad(rvec,data.flatten(),1e-2)\n",
    "        n = [sigm,np.linalg.norm(sym_grad-num_grad),np.linalg.norm(sym_grad-num_grad)/np.linalg.norm(num_grad)]\n",
    "        sigm = sigm*4.\n",
    "        res.append(n)\n",
    "    res = np.array(res)\n",
    "    np.set_printoptions(4)\n",
    "    print res\n",
    "    print 'mean:',res.mean(0)\n",
    "    print 'max:',res.max(0)\n",
    "    \n",
    "print 'precision for accurate grad'\n",
    "test_numeric(use_approx_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision for aprox grad\n",
      "get numerical gradient and compare it with symbolic\n",
      "sigma,|sym-num|,|sym-num|/|num|\n",
      "[[  1.0000e-05   9.0289e-04   1.1586e-02]\n",
      " [  4.0000e-05   5.4461e-04   6.8984e-03]\n",
      " [  1.6000e-04   2.2084e-03   3.0132e-02]\n",
      " [  6.4000e-04   9.0620e-04   1.0367e-02]\n",
      " [  2.5600e-03   2.2757e-03   1.6295e-02]\n",
      " [  1.0240e-02   5.4758e-04   3.3898e-03]\n",
      " [  4.0960e-02   3.9302e-04   3.1437e-03]\n",
      " [  1.6384e-01   1.3891e-03   9.3739e-03]\n",
      " [  6.5536e-01   6.8958e-04   6.6171e-03]\n",
      " [  2.6214e+00   2.5208e-03   6.7992e-03]]\n",
      "mean: [ 0.3495  0.0012  0.0105]\n",
      "max: [  2.6214e+00   2.5208e-03   3.0132e-02]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print 'precision for aprox grad'\n",
    "test_numeric(use_approx_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pergomance for accurate grad\n",
      "1 loop, best of 3: 204 ms per loop\n"
     ]
    }
   ],
   "source": [
    "gm_num=2\n",
    "ndim = 10\n",
    "X = T.fvector()\n",
    "gmm_op = T.sum(GMMOp(gm_num,ndim,use_approx_grad=False)(X))\n",
    "fg = function([X],[gmm_op]+T.grad(gmm_op,[X]),allow_input_downcast=True)\n",
    "print 'pergomance for accurate grad'\n",
    "%timeit fg(gen_mixture(np.array([1000 for i in range(gm_num)]),ndim,sigm=0.1)[0].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pergomance for approx grad\n",
      "10 loops, best of 3: 42.7 ms per loop\n"
     ]
    }
   ],
   "source": [
    "gm_num=2\n",
    "ndim = 10\n",
    "X = T.fvector()\n",
    "gmm_op = T.sum(GMMOp(gm_num,ndim,use_approx_grad=True)(X))\n",
    "fg = function([X],[gmm_op]+T.grad(gmm_op,[X]),allow_input_downcast=True)\n",
    "print 'pergomance for approx grad'\n",
    "%timeit fg(gen_mixture(np.array([1000 for i in range(gm_num)]),ndim,sigm=0.1)[0].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.56e-06   1.00e-10   2.26e-08]\n",
      " [  2.02e-06   9.35e-11   2.22e-08]\n",
      " [  7.90e+01   1.83e-03   9.70e-01]\n",
      " [  2.35e-06   1.22e-10   2.98e-08]\n",
      " [  2.06e-06   9.35e-11   2.98e-08]\n",
      " [  1.15e-06   5.10e-11   2.98e-08]\n",
      " [  6.40e+01   2.65e-03   6.52e-02]\n",
      " [  8.65e+01   1.39e-03   9.73e-01]\n",
      " [  6.14e+01   2.03e-03   3.57e-01]\n",
      " [  2.42e-06   8.57e-11   3.61e-09]]\n"
     ]
    }
   ],
   "source": [
    "def get_gmm_fit_test(gm_num,ndim,sigm=0.01):\n",
    "    X = T.fmatrix()\n",
    "    f = function([X],list(get_gmm(X,gm_num,ndim)),allow_input_downcast=True)\n",
    "    res = []\n",
    "    for i in range(10):\n",
    "        data,m,c,w = gen_mixture(np.random.randint(10,100,gm_num),ndim,sigm=sigm)\n",
    "        gmm = mixture.GaussianMixture(gm_num,covariance_type='diag',max_iter=2000).fit(data)\n",
    "        r = f(data)\n",
    "        n = [np.abs(gmm.means_-r[0]).sum(),np.abs(gmm.covariances_-r[1]).sum(),np.abs(gmm.weights_-r[2]).sum()]\n",
    "        res.append(n)\n",
    "    np.set_printoptions(2)\n",
    "    print np.array(res)\n",
    "get_gmm_fit_test(2,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
